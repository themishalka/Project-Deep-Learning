{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0570eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Sequence, Tuple, Union, Dict\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import keras_tuner as kt\n",
    "from dataclasses import dataclass, asdict\n",
    "import random\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492f5fe",
   "metadata": {},
   "source": [
    "Step 1: We load the expression, gene and sample data we saved after the pre-processing we applied in R. We aim to predict tumor grade from the RNAseq data, so we examine potential class imbalance in the tumor grade sample metadata column, and we remove NA values in tumors with unidentified grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e7e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load expression, genes and samples data\n",
    "expression=pd.read_csv(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_expression.csv\",index_col=0)\n",
    "genes=pd.read_csv(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_genes.csv\")\n",
    "samples = pyreadr.read_r(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_samples.rds\")\n",
    "samples = samples[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42b30a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ENSG00000276168.1', 'ENSG00000129824.16', 'ENSG00000133048.13',\n",
      "       'ENSG00000012223.13', 'ENSG00000198695.2'],\n",
      "      dtype='object')\n",
      "                              ENSG00000276168.1  ENSG00000129824.16  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07           8.423027           13.253145   \n",
      "TCGA-DU-7015-01A-11R-2027-07           8.252623            5.532866   \n",
      "\n",
      "                              ENSG00000133048.13  ENSG00000012223.13  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            7.491808            4.879747   \n",
      "TCGA-DU-7015-01A-11R-2027-07            8.707316            5.087127   \n",
      "\n",
      "                              ENSG00000198695.2  ENSG00000228253.1  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          15.950897          12.763416   \n",
      "TCGA-DU-7015-01A-11R-2027-07          16.922914          13.431528   \n",
      "\n",
      "                              ENSG00000198763.3  ENSG00000133110.15  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          17.025877            5.074539   \n",
      "TCGA-DU-7015-01A-11R-2027-07          17.670450            4.085189   \n",
      "\n",
      "                              ENSG00000198899.2  ENSG00000248527.1  ...  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          16.826818          13.863041  ...   \n",
      "TCGA-DU-7015-01A-11R-2027-07          17.706981          14.950704  ...   \n",
      "\n",
      "                              ENSG00000179796.12  ENSG00000240087.3  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            9.234303           4.836707   \n",
      "TCGA-DU-7015-01A-11R-2027-07            9.382020           5.434878   \n",
      "\n",
      "                              ENSG00000157087.20  ENSG00000164128.7  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07           11.285052           5.473512   \n",
      "TCGA-DU-7015-01A-11R-2027-07           12.349215           5.809448   \n",
      "\n",
      "                              ENSG00000170075.9  ENSG00000188783.6  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          14.468218          11.255899   \n",
      "TCGA-DU-7015-01A-11R-2027-07          13.080774          10.141038   \n",
      "\n",
      "                              ENSG00000112333.12  ENSG00000166819.12  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            8.641767            6.874675   \n",
      "TCGA-DU-7015-01A-11R-2027-07            8.065001            7.409357   \n",
      "\n",
      "                              ENSG00000116194.13  ENSG00000130988.13  \n",
      "TCGA-HT-7468-01A-11R-2027-07            8.731906            7.238853  \n",
      "TCGA-DU-7015-01A-11R-2027-07            9.466173            7.052062  \n",
      "\n",
      "[2 rows x 2000 columns]\n",
      "                                                   barcode       patient  \\\n",
      "rownames                                                                   \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015   \n",
      "\n",
      "                                        sample shortLetterCode  \\\n",
      "rownames                                                         \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A              TP   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A              TP   \n",
      "\n",
      "                                       definition sample_submitter_id  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07  Primary solid Tumor    TCGA-HT-7468-01A   \n",
      "TCGA-DU-7015-01A-11R-2027-07  Primary solid Tumor    TCGA-DU-7015-01A   \n",
      "\n",
      "                              intermediate_dimension tumor_descriptor  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07                     0.7          Primary   \n",
      "TCGA-DU-7015-01A-11R-2027-07                     1.0          Primary   \n",
      "\n",
      "                                                 sample_id  \\\n",
      "rownames                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A-11R-2027-07   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A-11R-2027-07   \n",
      "\n",
      "                                             pathology_report_uuid  ...  \\\n",
      "rownames                                                            ...   \n",
      "TCGA-HT-7468-01A-11R-2027-07  f56fcc2c-db3d-4ae5-b8dc-975b98fb4675  ...   \n",
      "TCGA-DU-7015-01A-11R-2027-07  15dbad7b-e2ae-42b0-92a1-5ccfc3090c2d  ...   \n",
      "\n",
      "                             paper_IDH.specific.RNA.Expression.Cluster  \\\n",
      "rownames                                                                 \n",
      "TCGA-HT-7468-01A-11R-2027-07                                 IDHmut-R1   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                 IDHmut-R3   \n",
      "\n",
      "                              paper_Pan.Glioma.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                 \n",
      "TCGA-HT-7468-01A-11R-2027-07                                      LGm3   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                      LGm2   \n",
      "\n",
      "                             paper_IDH.specific.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                  \n",
      "TCGA-HT-7468-01A-11R-2027-07                                  IDHmut-K3   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                  IDHmut-K2   \n",
      "\n",
      "                             paper_Supervised.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07                                    Codel   \n",
      "TCGA-DU-7015-01A-11R-2027-07                              G-CIMP-high   \n",
      "\n",
      "                              paper_Random.Forest.Sturm.Cluster  \\\n",
      "rownames                                                          \n",
      "TCGA-HT-7468-01A-11R-2027-07                                IDH   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                IDH   \n",
      "\n",
      "                             paper_RPPA.cluster  \\\n",
      "rownames                                          \n",
      "TCGA-HT-7468-01A-11R-2027-07                 K2   \n",
      "TCGA-DU-7015-01A-11R-2027-07                 K2   \n",
      "\n",
      "                             paper_Telomere.length.estimate.in.blood.normal..Kb.  \\\n",
      "rownames                                                                           \n",
      "TCGA-HT-7468-01A-11R-2027-07                                             5.4533    \n",
      "TCGA-DU-7015-01A-11R-2027-07                                                NaN    \n",
      "\n",
      "                              paper_Telomere.length.estimate.in.tumor..Kb.  \\\n",
      "rownames                                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07                                        2.5218   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                           NaN   \n",
      "\n",
      "                             tumor_type method_of_diagnosis  \n",
      "rownames                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07        LGG                 NaN  \n",
      "TCGA-DU-7015-01A-11R-2027-07        LGG                 NaN  \n",
      "\n",
      "[2 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "#check what the expression, genes and samples data look like\n",
    "print(expression.columns[:5])\n",
    "print(expression.head(2))\n",
    "print(samples.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cbcc870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(925, 114)\n",
      "tumor_grade\n",
      "G4    391\n",
      "G3    216\n",
      "G2    211\n",
      "Name: count, dtype: int64\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "#explore the samples metadata\n",
    "print(samples.shape)\n",
    "# list of column names\n",
    "samples.columns.tolist()\n",
    "\n",
    "#check for potential class imbalance in tumor grade\n",
    "print(samples[\"tumor_grade\"].value_counts())\n",
    "\n",
    "#count how many NA values are in the tumor grade column\n",
    "print(samples[\"tumor_grade\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7695a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we exclude samples with NA tumor grade\n",
    "samples_all = samples.copy() #keep original samples dataframe\n",
    "expression_all = expression.copy() #keep original expression dataframe\n",
    "\n",
    "samples_sup = samples_all.dropna(subset=[\"tumor_grade\"])\n",
    "expression_sup = expression_all.loc[samples_sup.index]\n",
    "\n",
    "assert expression_sup.shape[0] == samples_sup.shape[0], \"Mismatch in number of samples between expression and samples dataframes after dropping NA tumor grades.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09d5ad",
   "metadata": {},
   "source": [
    "Step 2: We configure the model and ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e796cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    out_dir: str = \"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\"\n",
    "    seed: int = 42\n",
    "\n",
    "    # labels\n",
    "    label_col: str = \"tumor_grade\"\n",
    "    label_map: dict = None  # set in main if None\n",
    "\n",
    "    # splits\n",
    "    test_size: float = 0.15\n",
    "    n_folds: int = 9  # 9-fold CV on train+val portion\n",
    "\n",
    "    # training/tuning\n",
    "    max_epochs: int = 100\n",
    "    early_stop_patience: int = 5\n",
    "\n",
    "    # tuner\n",
    "    hyperband_factor: int = 3\n",
    "    objective: str = \"val_accuracy\"\n",
    "\n",
    "def set_global_seed(seed: int) -> None:\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # makes TF ops more deterministic when possible\n",
    "    try:\n",
    "        tf.config.experimental.enable_op_determinism()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def make_run_dir(base_dir: str) -> str:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, ts)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d10a2",
   "metadata": {},
   "source": [
    "Step 3: We assign the classes. Grade II tumors will be 0, grade III will be 1 and grade IV will be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52b72236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_y(samples_sup: pd.DataFrame, label_col: str, label_map: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert tumor grade strings to integer classes.\n",
    "    Example mapping: {\"G2\":0, \"G3\":1, \"G4\":2}\n",
    "    \"\"\"\n",
    "    y = samples_sup[label_col].astype(str).map(label_map)\n",
    "    if y.isna().any():\n",
    "        bad = samples_sup.loc[y.isna(), label_col].unique()\n",
    "        raise ValueError(f\"Found unmapped labels: {bad}\")\n",
    "    return y.astype(int).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a5fbb",
   "metadata": {},
   "source": [
    "Step 4: We construct our  splits: we will have a hold-out test set, and run a 9-fold cross-validation on the rest of the data. In the cross-validation we include training and validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6420581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_holdout_test(X: pd.DataFrame, y: np.ndarray, cfg: Config):\n",
    "    \"\"\"\n",
    "    Hold out ONE stratified test set.\n",
    "    Remaining data is used for 9-fold CV (train/val folds).\n",
    "    \"\"\"\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=cfg.test_size,\n",
    "        random_state=cfg.seed,\n",
    "        stratify=y\n",
    "    )\n",
    "    return X_trainval, X_test, y_trainval, y_test\n",
    "\n",
    "def save_test_ids(run_dir: str, X_test: pd.DataFrame) -> None:\n",
    "    pd.Index(X_test.index).to_series().to_csv(os.path.join(run_dir, \"test_ids.csv\"), index=False)\n",
    "\n",
    "def save_fold_ids(run_dir: str, fold: int, X_train: pd.DataFrame, X_val: pd.DataFrame) -> None:\n",
    "    fold_dir = os.path.join(run_dir, f\"fold_{fold:02d}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "    pd.Index(X_train.index).to_series().to_csv(os.path.join(fold_dir, \"train_ids.csv\"), index=False)\n",
    "    pd.Index(X_val.index).to_series().to_csv(os.path.join(fold_dir, \"val_ids.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d257ba",
   "metadata": {},
   "source": [
    "Step 5: We standardize the data, fitting on test data only to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68c663e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_train_val(X_train: pd.DataFrame, X_val: pd.DataFrame):\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_s = scaler.fit_transform(X_train).astype(np.float32)\n",
    "    X_val_s = scaler.transform(X_val).astype(np.float32)\n",
    "    return X_train_s, X_val_s, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97070e",
   "metadata": {},
   "source": [
    "Step 6: We build our multi-layer perceptron model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b49462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp: kt.HyperParameters, input_dim: int, num_classes: int = 3) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build an MLP for 3-class classification with tunable hyperparameters.\n",
    "    \"\"\"\n",
    "    #batch size \n",
    "    hp.Choice(\"batch_size\", [16, 32, 64, 128])  # registered for the tuner\n",
    "\n",
    "    # architecture choices\n",
    "    n_layers = hp.Int(\"n_layers\", 1, 3)\n",
    "    units = hp.Choice(\"units\", [64, 128, 256, 512])\n",
    "    dropout = hp.Float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    l2_strength = hp.Choice(\"l2\", [0.0, 1e-5, 1e-4, 1e-3])\n",
    "\n",
    "    # optimizer choice\n",
    "    lr = hp.Choice(\"lr\", [1e-4, 3e-4, 1e-3, 3e-3])\n",
    "\n",
    "    \n",
    "    inputs = keras.Input(shape=(input_dim,), name=\"expression\")\n",
    "    x = inputs\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        x = layers.Dense(\n",
    "            units=units,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.l2(l2_strength),\n",
    "            name=f\"dense_{i+1}\"\n",
    "        )(x)\n",
    "        if dropout > 0:\n",
    "            x = layers.Dropout(dropout, name=f\"dropout_{i+1}\")(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"MLP_grade\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f1fa8",
   "metadata": {},
   "source": [
    "Step 7: We tune the hyper-paramaters to choose the best model and avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aea6b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperbandWithBatchSize(kt.Hyperband):\n",
    "    \"\"\"Hyperband tuner that automatically uses hp['batch_size'] when fitting.\"\"\"\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        hp = trial.hyperparameters\n",
    "        kwargs[\"batch_size\"] = hp.get(\"batch_size\")\n",
    "        return super().run_trial(trial, *args, **kwargs)\n",
    "\n",
    "def tune_hyperparameters(X_train_s, y_train, X_val_s, y_val, input_dim: int, run_dir: str, cfg: Config):\n",
    "    tuner_dir = os.path.join(run_dir, \"tuner\")\n",
    "    os.makedirs(tuner_dir, exist_ok=True)\n",
    "\n",
    "    tuner = HyperbandWithBatchSize(\n",
    "        hypermodel=lambda hp: build_model(hp, input_dim=input_dim, num_classes=3),\n",
    "        objective=kt.Objective(cfg.objective, direction=\"max\"),\n",
    "        max_epochs=cfg.max_epochs,\n",
    "        factor=cfg.hyperband_factor,\n",
    "        directory=tuner_dir,\n",
    "        project_name=\"grade_mlp\"\n",
    "    )\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        patience=cfg.early_stop_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        X_train_s, y_train,\n",
    "        validation_data=(X_val_s, y_val),\n",
    "        epochs=cfg.max_epochs,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "    return tuner, best_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801fd97",
   "metadata": {},
   "source": [
    "Step 8: We choose the best model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d6e18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best(X_train_s, y_train, X_val_s, y_val, input_dim: int, best_hp, run_dir: str, cfg: Config):\n",
    "    model = build_model(best_hp, input_dim=input_dim, num_classes=3)\n",
    "\n",
    "    ckpt_path = os.path.join(run_dir, \"best_model.keras\")\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        patience=cfg.early_stop_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=ckpt_path,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_s, y_train,\n",
    "        validation_data=(X_val_s, y_val),\n",
    "        epochs=cfg.max_epochs,\n",
    "        batch_size=best_hp.get(\"batch_size\"),\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(run_dir, \"history.json\"), \"w\") as f:\n",
    "        json.dump(history.history, f, indent=2)\n",
    "\n",
    "    return model, ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef7714",
   "metadata": {},
   "source": [
    "Step 9: We evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbaed84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: keras.Model, X_eval_s, y_eval, run_dir: str, prefix: str = \"eval\"):\n",
    "    eval_loss, eval_acc = model.evaluate(X_eval_s, y_eval, verbose=0)\n",
    "\n",
    "    probs = model.predict(X_eval_s, verbose=0)\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "\n",
    "    report = classification_report(y_eval, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_eval, y_pred).tolist()\n",
    "    macro_f1 = float(f1_score(y_eval, y_pred, average=\"macro\"))\n",
    "\n",
    "    results = {\n",
    "        \"loss\": float(eval_loss),\n",
    "        \"accuracy\": float(eval_acc),\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(run_dir, f\"{prefix}_metrics.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6d782",
   "metadata": {},
   "source": [
    "Step 10: We save all the run metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f9916f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_run_metadata(run_dir: str, cfg: Config, best_hp, scaler):\n",
    "    with open(os.path.join(run_dir, \"config.json\"), \"w\") as f:\n",
    "        json.dump(asdict(cfg), f, indent=2)\n",
    "\n",
    "    with open(os.path.join(run_dir, \"best_hyperparameters.json\"), \"w\") as f:\n",
    "        json.dump(best_hp.values, f, indent=2)\n",
    "\n",
    "    joblib.dump(scaler, os.path.join(run_dir, \"scaler.joblib\"))\n",
    "\n",
    "    versions = {\n",
    "        \"python\": f\"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}\",\n",
    "        \"numpy\": np.__version__,\n",
    "        \"pandas\": pd.__version__,\n",
    "        \"tensorflow\": tf.__version__,\n",
    "        \"keras_tuner\": kt.__version__\n",
    "    }\n",
    "    with open(os.path.join(run_dir, \"versions.json\"), \"w\") as f:\n",
    "        json.dump(versions, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3c5db",
   "metadata": {},
   "source": [
    "Final Step: Main run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75397e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(expression_sup: pd.DataFrame, samples_sup: pd.DataFrame):\n",
    "    cfg = Config()\n",
    "    if cfg.label_map is None:\n",
    "        cfg.label_map = {\"G2\": 0, \"G3\": 1, \"G4\": 2}\n",
    "\n",
    "    set_global_seed(cfg.seed)\n",
    "    run_dir = make_run_dir(cfg.out_dir)\n",
    "\n",
    "    # 1) labels\n",
    "    y = make_y(samples_sup, cfg.label_col, cfg.label_map)\n",
    "\n",
    "    # 2) hold-out test\n",
    "    X_trainval, X_test, y_trainval, y_test = split_holdout_test(expression_sup, y, cfg)\n",
    "    save_test_ids(run_dir, X_test)\n",
    "\n",
    "    # 3) 9-fold CV on trainval\n",
    "    skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "\n",
    "    cv_results = []\n",
    "    best_hp = None\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_trainval, y_trainval), start=1):\n",
    "        fold_dir = os.path.join(run_dir, f\"fold_{fold:02d}\")\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "        X_tr = X_trainval.iloc[tr_idx]\n",
    "        X_va = X_trainval.iloc[va_idx]\n",
    "        y_tr = y_trainval[tr_idx]\n",
    "        y_va = y_trainval[va_idx]\n",
    "\n",
    "        save_fold_ids(run_dir, fold, X_tr, X_va)\n",
    "\n",
    "        # standardize per-fold \n",
    "        X_tr_s, X_va_s, _scaler_fold = standardize_train_val(X_tr, X_va)\n",
    "\n",
    "        # tune once and reuse HP for all folds to save time\n",
    "        if best_hp is None:\n",
    "            tuner, best_hp = tune_hyperparameters(\n",
    "                X_tr_s, y_tr,\n",
    "                X_va_s, y_va,\n",
    "                input_dim=X_tr_s.shape[1],\n",
    "                run_dir=fold_dir,\n",
    "                cfg=cfg\n",
    "            )\n",
    "\n",
    "            with open(os.path.join(run_dir, \"best_hyperparameters.json\"), \"w\") as f:\n",
    "                json.dump(best_hp.values, f, indent=2)\n",
    "\n",
    "        # train best HP on this fold\n",
    "        model, ckpt_path = train_best(\n",
    "            X_tr_s, y_tr,\n",
    "            X_va_s, y_va,\n",
    "            input_dim=X_tr_s.shape[1],\n",
    "            best_hp=best_hp,\n",
    "            run_dir=fold_dir,\n",
    "            cfg=cfg\n",
    "        )\n",
    "\n",
    "        # evaluate on fold validation\n",
    "        fold_metrics = evaluate(model, X_va_s, y_va, fold_dir, prefix=\"val\")\n",
    "\n",
    "        cv_results.append({\n",
    "            \"fold\": fold,\n",
    "            \"val_accuracy\": fold_metrics[\"accuracy\"],\n",
    "            \"val_macro_f1\": fold_metrics[\"macro_f1\"],\n",
    "            \"model_path\": ckpt_path\n",
    "        })\n",
    "\n",
    "    with open(os.path.join(run_dir, \"cv_results.json\"), \"w\") as f:\n",
    "        json.dump(cv_results, f, indent=2)\n",
    "\n",
    "    # 4) final training on all trainval with a small internal val split for early stopping\n",
    "    X_tr_final, X_va_final, y_tr_final, y_va_final = train_test_split(\n",
    "        X_trainval, y_trainval,\n",
    "        test_size=0.15,\n",
    "        random_state=cfg.seed,\n",
    "        stratify=y_trainval\n",
    "    )\n",
    "\n",
    "    scaler_final = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_tr_final_s = scaler_final.fit_transform(X_tr_final).astype(np.float32)\n",
    "    X_va_final_s = scaler_final.transform(X_va_final).astype(np.float32)\n",
    "    X_test_s = scaler_final.transform(X_test).astype(np.float32)\n",
    "\n",
    "    final_dir = os.path.join(run_dir, \"final\")\n",
    "    os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "    model_final, ckpt_path_final = train_best(\n",
    "        X_tr_final_s, y_tr_final,\n",
    "        X_va_final_s, y_va_final,\n",
    "        input_dim=X_tr_final_s.shape[1],\n",
    "        best_hp=best_hp,\n",
    "        run_dir=final_dir,\n",
    "        cfg=cfg\n",
    "    )\n",
    "\n",
    "    # 5) evaluate once on held-out test\n",
    "    test_results = evaluate(model_final, X_test_s, y_test, final_dir, prefix=\"test\")\n",
    "\n",
    "    # 6) save metadata + final scaler\n",
    "    save_run_metadata(final_dir, cfg, best_hp, scaler_final)\n",
    "\n",
    "    # print summary\n",
    "    val_accs = [r[\"val_accuracy\"] for r in cv_results]\n",
    "    val_f1s = [r[\"val_macro_f1\"] for r in cv_results]\n",
    "\n",
    "    print(\"Saved run to:\", run_dir)\n",
    "    print(\"Final model:\", ckpt_path_final)\n",
    "    print(f\"CV val accuracy: mean={np.mean(val_accs):.4f} std={np.std(val_accs):.4f}\")\n",
    "    print(f\"CV val macro F1: mean={np.mean(val_f1s):.4f} std={np.std(val_f1s):.4f}\")\n",
    "    print(\"Test accuracy:\", test_results[\"accuracy\"])\n",
    "    print(\"Test macro F1:\", test_results[\"macro_f1\"])\n",
    "\n",
    "    return test_results, run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a633a18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 17s]\n",
      "val_accuracy: 0.807692289352417\n",
      "\n",
      "Best val_accuracy So Far: 0.8589743375778198\n",
      "Total elapsed time: 01h 07m 01s\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5365 - loss: 1.3546 - val_accuracy: 0.7179 - val_loss: 0.7063\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6742 - loss: 0.8854 - val_accuracy: 0.7308 - val_loss: 0.6638\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7585 - loss: 0.7054 - val_accuracy: 0.7179 - val_loss: 0.6273\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7909 - loss: 0.6180 - val_accuracy: 0.7179 - val_loss: 0.6107\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.5945 - val_accuracy: 0.7436 - val_loss: 0.6124\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8298 - loss: 0.5359 - val_accuracy: 0.7308 - val_loss: 0.6019\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8395 - loss: 0.5136 - val_accuracy: 0.7436 - val_loss: 0.5945\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8574 - loss: 0.4562 - val_accuracy: 0.7564 - val_loss: 0.5764\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8736 - loss: 0.4318 - val_accuracy: 0.8077 - val_loss: 0.5818\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8768 - loss: 0.4278 - val_accuracy: 0.7692 - val_loss: 0.5933\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8801 - loss: 0.4205 - val_accuracy: 0.7564 - val_loss: 0.5985\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8833 - loss: 0.3930 - val_accuracy: 0.7949 - val_loss: 0.5857\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8833 - loss: 0.3882 - val_accuracy: 0.7949 - val_loss: 0.5912\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.3781 - val_accuracy: 0.7821 - val_loss: 0.5926\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001619B272340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001619B272340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6126 - loss: 1.0960 - val_accuracy: 0.7436 - val_loss: 0.7416\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7277 - loss: 0.7764 - val_accuracy: 0.7692 - val_loss: 0.6307\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7909 - loss: 0.6225 - val_accuracy: 0.7692 - val_loss: 0.5771\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8006 - loss: 0.5967 - val_accuracy: 0.7564 - val_loss: 0.5613\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7893 - loss: 0.5604 - val_accuracy: 0.7949 - val_loss: 0.5398\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8201 - loss: 0.5307 - val_accuracy: 0.7949 - val_loss: 0.5313\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8379 - loss: 0.4737 - val_accuracy: 0.8205 - val_loss: 0.5167\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8574 - loss: 0.4725 - val_accuracy: 0.8333 - val_loss: 0.5100\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8444 - loss: 0.4487 - val_accuracy: 0.8462 - val_loss: 0.5080\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8833 - loss: 0.4048 - val_accuracy: 0.8333 - val_loss: 0.5005\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8833 - loss: 0.3963 - val_accuracy: 0.8205 - val_loss: 0.4975\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8882 - loss: 0.4082 - val_accuracy: 0.8333 - val_loss: 0.5001\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8979 - loss: 0.3751 - val_accuracy: 0.8333 - val_loss: 0.4885\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8768 - loss: 0.3778 - val_accuracy: 0.8462 - val_loss: 0.4747\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.6165 - loss: 1.0528 - val_accuracy: 0.7273 - val_loss: 0.6755\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7330 - loss: 0.7585 - val_accuracy: 0.7922 - val_loss: 0.6195\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7702 - loss: 0.6135 - val_accuracy: 0.7922 - val_loss: 0.5697\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7880 - loss: 0.5641 - val_accuracy: 0.7792 - val_loss: 0.5454\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8123 - loss: 0.5295 - val_accuracy: 0.8442 - val_loss: 0.5123\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8155 - loss: 0.5029 - val_accuracy: 0.8182 - val_loss: 0.5037\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8528 - loss: 0.4395 - val_accuracy: 0.8182 - val_loss: 0.4977\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8366 - loss: 0.4501 - val_accuracy: 0.8182 - val_loss: 0.4869\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8786 - loss: 0.4216 - val_accuracy: 0.8571 - val_loss: 0.4729\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8851 - loss: 0.4021 - val_accuracy: 0.8182 - val_loss: 0.4644\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8786 - loss: 0.4002 - val_accuracy: 0.8182 - val_loss: 0.4606\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.3844 - val_accuracy: 0.8182 - val_loss: 0.4628\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8916 - loss: 0.3740 - val_accuracy: 0.8571 - val_loss: 0.4581\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8948 - loss: 0.3553 - val_accuracy: 0.8442 - val_loss: 0.4613\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5955 - loss: 1.1455 - val_accuracy: 0.6623 - val_loss: 0.7852\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7330 - loss: 0.8033 - val_accuracy: 0.7403 - val_loss: 0.6350\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7168 - loss: 0.7362 - val_accuracy: 0.7662 - val_loss: 0.5952\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7735 - loss: 0.6415 - val_accuracy: 0.7922 - val_loss: 0.5531\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7913 - loss: 0.5982 - val_accuracy: 0.8052 - val_loss: 0.5409\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8252 - loss: 0.5481 - val_accuracy: 0.7922 - val_loss: 0.5189\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8301 - loss: 0.5062 - val_accuracy: 0.8052 - val_loss: 0.5140\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8495 - loss: 0.4747 - val_accuracy: 0.8312 - val_loss: 0.4995\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.4670 - val_accuracy: 0.8052 - val_loss: 0.5113\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.4392 - val_accuracy: 0.8052 - val_loss: 0.5039\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8786 - loss: 0.4246 - val_accuracy: 0.8312 - val_loss: 0.4864\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8657 - loss: 0.4213 - val_accuracy: 0.8571 - val_loss: 0.4767\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8835 - loss: 0.4159 - val_accuracy: 0.8182 - val_loss: 0.4790\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8835 - loss: 0.3956 - val_accuracy: 0.8182 - val_loss: 0.4720\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8964 - loss: 0.3856 - val_accuracy: 0.8182 - val_loss: 0.4688\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8932 - loss: 0.3689 - val_accuracy: 0.8442 - val_loss: 0.4662\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8932 - loss: 0.3687 - val_accuracy: 0.8442 - val_loss: 0.4613\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 1.2393 - val_accuracy: 0.6623 - val_loss: 0.7917\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7039 - loss: 0.8545 - val_accuracy: 0.7273 - val_loss: 0.6918\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7476 - loss: 0.7085 - val_accuracy: 0.7662 - val_loss: 0.6399\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7832 - loss: 0.6125 - val_accuracy: 0.8052 - val_loss: 0.6095\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7735 - loss: 0.5884 - val_accuracy: 0.8182 - val_loss: 0.5714\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8123 - loss: 0.5203 - val_accuracy: 0.8312 - val_loss: 0.5496\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.4948 - val_accuracy: 0.8312 - val_loss: 0.5198\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.4710 - val_accuracy: 0.8701 - val_loss: 0.5063\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8511 - loss: 0.4608 - val_accuracy: 0.8701 - val_loss: 0.4823\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8673 - loss: 0.4498 - val_accuracy: 0.8701 - val_loss: 0.4857\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8770 - loss: 0.4202 - val_accuracy: 0.8831 - val_loss: 0.4704\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8916 - loss: 0.3861 - val_accuracy: 0.8831 - val_loss: 0.4663\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8835 - loss: 0.3921 - val_accuracy: 0.8961 - val_loss: 0.4536\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8883 - loss: 0.3890 - val_accuracy: 0.8831 - val_loss: 0.4514\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9256 - loss: 0.3508 - val_accuracy: 0.8701 - val_loss: 0.4442\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9110 - loss: 0.3685 - val_accuracy: 0.8831 - val_loss: 0.4362\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9142 - loss: 0.3499 - val_accuracy: 0.8831 - val_loss: 0.4308\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9126 - loss: 0.3372 - val_accuracy: 0.8961 - val_loss: 0.4149\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5874 - loss: 1.0896 - val_accuracy: 0.7922 - val_loss: 0.7418\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7314 - loss: 0.7735 - val_accuracy: 0.7922 - val_loss: 0.6285\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7411 - loss: 0.6415 - val_accuracy: 0.7922 - val_loss: 0.5882\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7848 - loss: 0.6068 - val_accuracy: 0.8052 - val_loss: 0.5653\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7880 - loss: 0.5746 - val_accuracy: 0.8312 - val_loss: 0.5543\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.5145 - val_accuracy: 0.8182 - val_loss: 0.5423\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8285 - loss: 0.4861 - val_accuracy: 0.8312 - val_loss: 0.5285\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8592 - loss: 0.4434 - val_accuracy: 0.8571 - val_loss: 0.5238\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8641 - loss: 0.4276 - val_accuracy: 0.8442 - val_loss: 0.5207\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8657 - loss: 0.4303 - val_accuracy: 0.8571 - val_loss: 0.5081\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8851 - loss: 0.4065 - val_accuracy: 0.8701 - val_loss: 0.5035\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8786 - loss: 0.3902 - val_accuracy: 0.8571 - val_loss: 0.4917\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8932 - loss: 0.3880 - val_accuracy: 0.8571 - val_loss: 0.4914\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.3619 - val_accuracy: 0.8701 - val_loss: 0.5008\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9029 - loss: 0.3683 - val_accuracy: 0.8571 - val_loss: 0.4912\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9078 - loss: 0.3649 - val_accuracy: 0.8571 - val_loss: 0.4849\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4871 - loss: 1.4383 - val_accuracy: 0.7662 - val_loss: 0.8303\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7006 - loss: 0.8717 - val_accuracy: 0.7532 - val_loss: 0.7919\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7395 - loss: 0.7499 - val_accuracy: 0.7922 - val_loss: 0.6705\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7929 - loss: 0.6268 - val_accuracy: 0.7792 - val_loss: 0.6389\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7977 - loss: 0.5681 - val_accuracy: 0.7532 - val_loss: 0.6270\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.5355 - val_accuracy: 0.7662 - val_loss: 0.5922\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.5382 - val_accuracy: 0.7792 - val_loss: 0.5880\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8430 - loss: 0.4656 - val_accuracy: 0.7662 - val_loss: 0.5610\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6019 - loss: 1.1522 - val_accuracy: 0.8182 - val_loss: 0.5877\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7265 - loss: 0.7923 - val_accuracy: 0.8442 - val_loss: 0.5492\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7233 - loss: 0.6784 - val_accuracy: 0.8312 - val_loss: 0.5272\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7961 - loss: 0.5806 - val_accuracy: 0.8442 - val_loss: 0.5051\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8188 - loss: 0.5391 - val_accuracy: 0.8831 - val_loss: 0.4903\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8172 - loss: 0.5180 - val_accuracy: 0.8831 - val_loss: 0.4879\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8252 - loss: 0.4912 - val_accuracy: 0.8701 - val_loss: 0.4820\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8511 - loss: 0.4580 - val_accuracy: 0.8701 - val_loss: 0.4752\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8706 - loss: 0.4271 - val_accuracy: 0.8701 - val_loss: 0.4612\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8511 - loss: 0.4338 - val_accuracy: 0.8831 - val_loss: 0.4485\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4142 - loss: 1.7002 - val_accuracy: 0.6494 - val_loss: 0.9945\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7006 - loss: 0.8818 - val_accuracy: 0.6753 - val_loss: 0.7989\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7540 - loss: 0.7421 - val_accuracy: 0.7273 - val_loss: 0.7100\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7346 - loss: 0.6966 - val_accuracy: 0.7922 - val_loss: 0.6553\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7751 - loss: 0.6194 - val_accuracy: 0.7922 - val_loss: 0.6368\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7977 - loss: 0.5469 - val_accuracy: 0.8052 - val_loss: 0.6133\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.5291 - val_accuracy: 0.7922 - val_loss: 0.6124\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.5007 - val_accuracy: 0.8052 - val_loss: 0.6066\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8447 - loss: 0.4722 - val_accuracy: 0.8182 - val_loss: 0.5818\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8641 - loss: 0.4448 - val_accuracy: 0.8442 - val_loss: 0.5804\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8900 - loss: 0.4132 - val_accuracy: 0.8442 - val_loss: 0.5708\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.4070 - val_accuracy: 0.8312 - val_loss: 0.5633\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8916 - loss: 0.3996 - val_accuracy: 0.8312 - val_loss: 0.5611\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8900 - loss: 0.4006 - val_accuracy: 0.8312 - val_loss: 0.5678\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9061 - loss: 0.3652 - val_accuracy: 0.8442 - val_loss: 0.5567\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.6000 - loss: 1.1158 - val_accuracy: 0.7524 - val_loss: 0.6927\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7153 - loss: 0.7974 - val_accuracy: 0.7810 - val_loss: 0.6131\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7576 - loss: 0.6921 - val_accuracy: 0.7524 - val_loss: 0.5658\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7644 - loss: 0.6558 - val_accuracy: 0.7714 - val_loss: 0.5271\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8119 - loss: 0.5445 - val_accuracy: 0.8286 - val_loss: 0.5053\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8136 - loss: 0.5530 - val_accuracy: 0.8190 - val_loss: 0.5017\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8136 - loss: 0.4957 - val_accuracy: 0.8381 - val_loss: 0.4937\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8441 - loss: 0.4671 - val_accuracy: 0.8381 - val_loss: 0.4871\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8407 - loss: 0.4522 - val_accuracy: 0.8381 - val_loss: 0.4755\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8390 - loss: 0.4500 - val_accuracy: 0.8476 - val_loss: 0.4719\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8864 - loss: 0.4178 - val_accuracy: 0.8381 - val_loss: 0.4656\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.3874 - val_accuracy: 0.8190 - val_loss: 0.4604\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8915 - loss: 0.3870 - val_accuracy: 0.8381 - val_loss: 0.4527\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8949 - loss: 0.3820 - val_accuracy: 0.8476 - val_loss: 0.4439\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9068 - loss: 0.3691 - val_accuracy: 0.8571 - val_loss: 0.4392\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9186 - loss: 0.3409 - val_accuracy: 0.8571 - val_loss: 0.4365\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8898 - loss: 0.3710 - val_accuracy: 0.8476 - val_loss: 0.4322\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9153 - loss: 0.3446 - val_accuracy: 0.8667 - val_loss: 0.4325\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3597 - val_accuracy: 0.8667 - val_loss: 0.4323\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9220 - loss: 0.3241 - val_accuracy: 0.8571 - val_loss: 0.4284\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9322 - loss: 0.3117 - val_accuracy: 0.8476 - val_loss: 0.4224\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9305 - loss: 0.3151 - val_accuracy: 0.8667 - val_loss: 0.4222\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9373 - loss: 0.3078 - val_accuracy: 0.8667 - val_loss: 0.4220\n",
      "Saved run to: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\\20251229_120944\n",
      "Final model: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\\20251229_120944\\final\\best_model.keras\n",
      "CV val accuracy: mean=0.8504 std=0.0315\n",
      "CV val macro F1: mean=0.8117 std=0.0450\n",
      "Test accuracy: 0.8292682766914368\n",
      "Test macro F1: 0.7791537667698658\n"
     ]
    }
   ],
   "source": [
    "#Now we call the main function to run the entire pipeline\n",
    "results, run_dir = main(expression_sup, samples_sup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "956d5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20251229_120944\\confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "#we can now access the saved metrics to produce evaluation reports and plots\n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20251229_120944\" \n",
    "final_dir = os.path.join(run_dir, \"final\")\n",
    "\n",
    "  \n",
    "\n",
    "# Load metrics\n",
    "with open(os.path.join(final_dir, \"test_metrics.json\"), \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "cm = np.array(metrics[\"confusion_matrix\"])\n",
    "class_names = [\"G2\", \"G3\", \"G4\"]  # must match your label mapping\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, out_path):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm)\n",
    "\n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_yticks(range(len(class_names)))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_confusion_matrix(cm, class_names, os.path.join(run_dir, \"confusion_matrix.png\"))\n",
    "print(\"Saved:\", os.path.join(run_dir, \"confusion_matrix.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded4a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MLP_grade\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MLP_grade\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ expression (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ expression (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m128,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384,779</span> (1.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m384,779\u001b[0m (1.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,259</span> (501.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,259\u001b[0m (501.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256,520</span> (1002.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m256,520\u001b[0m (1002.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at the best model \n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20251229_120944\"\n",
    "model_path = os.path.join(run_dir, \"final\", \"best_model.keras\")\n",
    "\n",
    "model = load_model(model_path)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
