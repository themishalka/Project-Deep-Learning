{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0570eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Sequence, Tuple, Union, Dict\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import keras_tuner as kt\n",
    "from dataclasses import dataclass, asdict\n",
    "import random\n",
    "from datetime import datetime\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492f5fe",
   "metadata": {},
   "source": [
    "Step 1: We load the expression, gene and sample data we saved after the pre-processing we applied in R. We aim to predict tumor grade from the RNAseq data, so we examine potential class imbalance in the tumor grade sample metadata column, and we remove NA values in tumors with unidentified grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e7e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load expression, genes and samples data\n",
    "expression=pd.read_csv(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_expression.csv\",index_col=0)\n",
    "genes=pd.read_csv(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_genes.csv\")\n",
    "samples = pyreadr.read_r(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_samples.rds\")\n",
    "samples = samples[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b30a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ENSG00000276168.1', 'ENSG00000129824.16', 'ENSG00000133048.13',\n",
      "       'ENSG00000012223.13', 'ENSG00000198695.2'],\n",
      "      dtype='object')\n",
      "                              ENSG00000276168.1  ENSG00000129824.16  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07           8.423027           13.253145   \n",
      "TCGA-DU-7015-01A-11R-2027-07           8.252623            5.532866   \n",
      "\n",
      "                              ENSG00000133048.13  ENSG00000012223.13  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            7.491808            4.879747   \n",
      "TCGA-DU-7015-01A-11R-2027-07            8.707316            5.087127   \n",
      "\n",
      "                              ENSG00000198695.2  ENSG00000228253.1  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          15.950897          12.763416   \n",
      "TCGA-DU-7015-01A-11R-2027-07          16.922914          13.431528   \n",
      "\n",
      "                              ENSG00000198763.3  ENSG00000133110.15  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          17.025877            5.074539   \n",
      "TCGA-DU-7015-01A-11R-2027-07          17.670450            4.085189   \n",
      "\n",
      "                              ENSG00000198899.2  ENSG00000248527.1  ...  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          16.826818          13.863041  ...   \n",
      "TCGA-DU-7015-01A-11R-2027-07          17.706981          14.950704  ...   \n",
      "\n",
      "                              ENSG00000179796.12  ENSG00000240087.3  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            9.234303           4.836707   \n",
      "TCGA-DU-7015-01A-11R-2027-07            9.382020           5.434878   \n",
      "\n",
      "                              ENSG00000157087.20  ENSG00000164128.7  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07           11.285052           5.473512   \n",
      "TCGA-DU-7015-01A-11R-2027-07           12.349215           5.809448   \n",
      "\n",
      "                              ENSG00000170075.9  ENSG00000188783.6  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          14.468218          11.255899   \n",
      "TCGA-DU-7015-01A-11R-2027-07          13.080774          10.141038   \n",
      "\n",
      "                              ENSG00000112333.12  ENSG00000166819.12  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            8.641767            6.874675   \n",
      "TCGA-DU-7015-01A-11R-2027-07            8.065001            7.409357   \n",
      "\n",
      "                              ENSG00000116194.13  ENSG00000130988.13  \n",
      "TCGA-HT-7468-01A-11R-2027-07            8.731906            7.238853  \n",
      "TCGA-DU-7015-01A-11R-2027-07            9.466173            7.052062  \n",
      "\n",
      "[2 rows x 2000 columns]\n",
      "                                                   barcode       patient  \\\n",
      "rownames                                                                   \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015   \n",
      "\n",
      "                                        sample shortLetterCode  \\\n",
      "rownames                                                         \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A              TP   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A              TP   \n",
      "\n",
      "                                       definition sample_submitter_id  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07  Primary solid Tumor    TCGA-HT-7468-01A   \n",
      "TCGA-DU-7015-01A-11R-2027-07  Primary solid Tumor    TCGA-DU-7015-01A   \n",
      "\n",
      "                              intermediate_dimension tumor_descriptor  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07                     0.7          Primary   \n",
      "TCGA-DU-7015-01A-11R-2027-07                     1.0          Primary   \n",
      "\n",
      "                                                 sample_id  \\\n",
      "rownames                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A-11R-2027-07   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A-11R-2027-07   \n",
      "\n",
      "                                             pathology_report_uuid  ...  \\\n",
      "rownames                                                            ...   \n",
      "TCGA-HT-7468-01A-11R-2027-07  f56fcc2c-db3d-4ae5-b8dc-975b98fb4675  ...   \n",
      "TCGA-DU-7015-01A-11R-2027-07  15dbad7b-e2ae-42b0-92a1-5ccfc3090c2d  ...   \n",
      "\n",
      "                             paper_IDH.specific.RNA.Expression.Cluster  \\\n",
      "rownames                                                                 \n",
      "TCGA-HT-7468-01A-11R-2027-07                                 IDHmut-R1   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                 IDHmut-R3   \n",
      "\n",
      "                              paper_Pan.Glioma.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                 \n",
      "TCGA-HT-7468-01A-11R-2027-07                                      LGm3   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                      LGm2   \n",
      "\n",
      "                             paper_IDH.specific.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                  \n",
      "TCGA-HT-7468-01A-11R-2027-07                                  IDHmut-K3   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                  IDHmut-K2   \n",
      "\n",
      "                             paper_Supervised.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07                                    Codel   \n",
      "TCGA-DU-7015-01A-11R-2027-07                              G-CIMP-high   \n",
      "\n",
      "                              paper_Random.Forest.Sturm.Cluster  \\\n",
      "rownames                                                          \n",
      "TCGA-HT-7468-01A-11R-2027-07                                IDH   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                IDH   \n",
      "\n",
      "                             paper_RPPA.cluster  \\\n",
      "rownames                                          \n",
      "TCGA-HT-7468-01A-11R-2027-07                 K2   \n",
      "TCGA-DU-7015-01A-11R-2027-07                 K2   \n",
      "\n",
      "                             paper_Telomere.length.estimate.in.blood.normal..Kb.  \\\n",
      "rownames                                                                           \n",
      "TCGA-HT-7468-01A-11R-2027-07                                             5.4533    \n",
      "TCGA-DU-7015-01A-11R-2027-07                                                NaN    \n",
      "\n",
      "                              paper_Telomere.length.estimate.in.tumor..Kb.  \\\n",
      "rownames                                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07                                        2.5218   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                           NaN   \n",
      "\n",
      "                             tumor_type method_of_diagnosis  \n",
      "rownames                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07        LGG                 NaN  \n",
      "TCGA-DU-7015-01A-11R-2027-07        LGG                 NaN  \n",
      "\n",
      "[2 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "#check what the expression, genes and samples data look like\n",
    "print(expression.columns[:5])\n",
    "print(expression.head(2))\n",
    "print(samples.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbcc870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(925, 114)\n",
      "tumor_grade\n",
      "G4    391\n",
      "G3    216\n",
      "G2    211\n",
      "Name: count, dtype: int64\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "#explore the samples metadata\n",
    "print(samples.shape)\n",
    "# list of column names\n",
    "samples.columns.tolist()\n",
    "\n",
    "#check for potential class imbalance in tumor grade\n",
    "print(samples[\"tumor_grade\"].value_counts())\n",
    "\n",
    "#count how many NA values are in the tumor grade column\n",
    "print(samples[\"tumor_grade\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7695a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we exclude samples with NA tumor grade\n",
    "samples_all = samples.copy() #keep original samples dataframe\n",
    "expression_all = expression.copy() #keep original expression dataframe\n",
    "\n",
    "samples_sup = samples_all.dropna(subset=[\"tumor_grade\"])\n",
    "expression_sup = expression_all.loc[samples_sup.index]\n",
    "\n",
    "assert expression_sup.shape[0] == samples_sup.shape[0], \"Mismatch in number of samples between expression and samples dataframes after dropping NA tumor grades.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09d5ad",
   "metadata": {},
   "source": [
    "Step 2: We configure the model and ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e796cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    out_dir: str = \"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\"\n",
    "    seed: int = 42\n",
    "\n",
    "    # labels\n",
    "    label_col: str = \"tumor_grade\"\n",
    "    label_map: dict = None  # set in main if None\n",
    "\n",
    "    # splits\n",
    "    test_size: float = 0.15\n",
    "    val_size: float = 0.15  # fraction of full dataset\n",
    "\n",
    "    # training/tuning\n",
    "    max_epochs: int = 100\n",
    "    early_stop_patience: int = 5\n",
    "\n",
    "    # tuner\n",
    "    hyperband_factor: int = 3\n",
    "    objective: str = \"val_accuracy\"\n",
    "\n",
    "def set_global_seed(seed: int) -> None:\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # makes TF ops more deterministic when possible\n",
    "    try:\n",
    "        tf.config.experimental.enable_op_determinism()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def make_run_dir(base_dir: str) -> str:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, ts)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d10a2",
   "metadata": {},
   "source": [
    "Step 3: We assign the classes. Grade II tumors will be 0, grade III will be 1 and grade IV will be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b72236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_y(samples_sup: pd.DataFrame, label_col: str, label_map: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert tumor grade strings to integer classes.\n",
    "    Example mapping: {\"G2\":0, \"G3\":1, \"G4\":2}\n",
    "    \"\"\"\n",
    "    y = samples_sup[label_col].astype(str).map(label_map)\n",
    "    if y.isna().any():\n",
    "        bad = samples_sup.loc[y.isna(), label_col].unique()\n",
    "        raise ValueError(f\"Found unmapped labels: {bad}\")\n",
    "    return y.astype(int).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a5fbb",
   "metadata": {},
   "source": [
    "Step 4: We construct our 3 splits: a training set, a validation set and a separate testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6420581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(X: pd.DataFrame, y: np.ndarray, cfg: Config):\n",
    "    \"\"\"\n",
    "    3-way stratified split.\n",
    "    1) split off test\n",
    "    2) split remaining into train/val\n",
    "    \"\"\"\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=cfg.test_size,\n",
    "        random_state=cfg.seed,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    # val_size is fraction of full dataset; convert to fraction of remaining temp\n",
    "    val_frac_of_temp = cfg.val_size / (1.0 - cfg.test_size)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=val_frac_of_temp,\n",
    "        random_state=cfg.seed,\n",
    "        stratify=y_temp\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "#we save the split ids to enable reproducibility\n",
    "def save_split_ids(run_dir: str, X_train: pd.DataFrame, X_val: pd.DataFrame, X_test: pd.DataFrame) -> None:\n",
    "    pd.Index(X_train.index).to_series().to_csv(os.path.join(run_dir, \"train_ids.csv\"), index=False)\n",
    "    pd.Index(X_val.index).to_series().to_csv(os.path.join(run_dir, \"val_ids.csv\"), index=False)\n",
    "    pd.Index(X_test.index).to_series().to_csv(os.path.join(run_dir, \"test_ids.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d257ba",
   "metadata": {},
   "source": [
    "Step 5: We standardize the data, fitting on test data only to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c663e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train: pd.DataFrame, X_val: pd.DataFrame, X_test: pd.DataFrame):\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_s = scaler.fit_transform(X_train).astype(np.float32)\n",
    "    X_val_s = scaler.transform(X_val).astype(np.float32)\n",
    "    X_test_s = scaler.transform(X_test).astype(np.float32)\n",
    "    return X_train_s, X_val_s, X_test_s, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97070e",
   "metadata": {},
   "source": [
    "Step 6: We build our multi-layer perceptron model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp: kt.HyperParameters, input_dim: int, num_classes: int = 3) -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build an MLP for 3-class classification with tunable hyperparameters.\n",
    "    \"\"\"\n",
    "    #batch size \n",
    "    hp.Choice(\"batch_size\", [16, 32, 64, 128])  # registered for the tuner\n",
    "\n",
    "    # architecture choices\n",
    "    n_layers = hp.Int(\"n_layers\", 1, 3)\n",
    "    units = hp.Choice(\"units\", [64, 128, 256, 512])\n",
    "    dropout = hp.Float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    l2_strength = hp.Choice(\"l2\", [0.0, 1e-5, 1e-4, 1e-3])\n",
    "\n",
    "    # optimizer choice\n",
    "    lr = hp.Choice(\"lr\", [1e-4, 3e-4, 1e-3, 3e-3])\n",
    "\n",
    "    \n",
    "    inputs = keras.Input(shape=(input_dim,), name=\"expression\")\n",
    "    x = inputs\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        x = layers.Dense(\n",
    "            units=units,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.l2(l2_strength),\n",
    "            name=f\"dense_{i+1}\"\n",
    "        )(x)\n",
    "        if dropout > 0:\n",
    "            x = layers.Dropout(dropout, name=f\"dropout_{i+1}\")(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"MLP_grade\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f1fa8",
   "metadata": {},
   "source": [
    "Step 7: We tune the hyper-paramaters to choose the best model and avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea6b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(X_train_s, y_train, X_val_s, y_val, input_dim: int, run_dir: str, cfg: Config):\n",
    "    tuner_dir = os.path.join(run_dir, \"tuner\")\n",
    "    os.makedirs(tuner_dir, exist_ok=True)\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        hypermodel=lambda hp: build_model(hp, input_dim=input_dim, num_classes=3),\n",
    "        objective=kt.Objective(cfg.objective, direction=\"max\"),\n",
    "        max_epochs=cfg.max_epochs,\n",
    "        factor=cfg.hyperband_factor,\n",
    "        directory=tuner_dir,\n",
    "        project_name=\"grade_mlp\"\n",
    "    )\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        patience=cfg.early_stop_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Tune batch size as well\n",
    "    # We choose from common values.\n",
    "    def fit_kwargs(hp):\n",
    "        return {\"batch_size\": hp.Choice(\"batch_size\", [16, 32, 64, 128])}\n",
    "\n",
    "    tuner.search(\n",
    "        X_train_s, y_train,\n",
    "        validation_data=(X_val_s, y_val),\n",
    "        epochs=cfg.max_epochs,\n",
    "        callbacks=[early_stop],\n",
    "        **fit_kwargs(tuner.oracle.get_space())\n",
    "    )\n",
    "\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "    return tuner, best_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801fd97",
   "metadata": {},
   "source": [
    "Step 8: We choose the best model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d6e18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best(X_train_s, y_train, X_val_s, y_val, input_dim: int, best_hp, run_dir: str, cfg: Config):\n",
    "    model = build_model(best_hp, input_dim=input_dim, num_classes=3)\n",
    "\n",
    "    ckpt_path = os.path.join(run_dir, \"best_model.keras\")\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        patience=cfg.early_stop_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=ckpt_path,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_s, y_train,\n",
    "        validation_data=(X_val_s, y_val),\n",
    "        epochs=cfg.max_epochs,\n",
    "        batch_size=best_hp.get(\"batch_size\"),\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save history\n",
    "    with open(os.path.join(run_dir, \"history.json\"), \"w\") as f:\n",
    "        json.dump(history.history, f, indent=2)\n",
    "\n",
    "    return model, ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef7714",
   "metadata": {},
   "source": [
    "Step 9: We evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbaed84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: keras.Model, X_test_s, y_test, run_dir: str):\n",
    "    test_loss, test_acc = model.evaluate(X_test_s, y_test, verbose=0)\n",
    "\n",
    "    probs = model.predict(X_test_s, verbose=0)\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
    "    macro_f1 = float(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "    results = {\n",
    "        \"test_loss\": float(test_loss),\n",
    "        \"test_accuracy\": float(test_acc),\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(run_dir, \"test_metrics.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6d782",
   "metadata": {},
   "source": [
    "Step 10: We save all the run metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f9916f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_run_metadata(run_dir: str, cfg: Config, best_hp, scaler):\n",
    "    with open(os.path.join(run_dir, \"config.json\"), \"w\") as f:\n",
    "        json.dump(asdict(cfg), f, indent=2)\n",
    "\n",
    "    with open(os.path.join(run_dir, \"best_hyperparameters.json\"), \"w\") as f:\n",
    "        json.dump(best_hp.values, f, indent=2)\n",
    "\n",
    "    joblib.dump(scaler, os.path.join(run_dir, \"scaler.joblib\"))\n",
    "\n",
    "    versions = {\n",
    "        \"python\": f\"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}\",\n",
    "        \"numpy\": np.__version__,\n",
    "        \"pandas\": pd.__version__,\n",
    "        \"tensorflow\": tf.__version__,\n",
    "        \"keras_tuner\": kt.__version__\n",
    "    }\n",
    "    with open(os.path.join(run_dir, \"versions.json\"), \"w\") as f:\n",
    "        json.dump(versions, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3c5db",
   "metadata": {},
   "source": [
    "Final Step: Main run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75397e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(expression_sup: pd.DataFrame, samples_sup: pd.DataFrame):\n",
    "    cfg = Config()\n",
    "    if cfg.label_map is None:\n",
    "        cfg.label_map = {\"G2\": 0, \"G3\": 1, \"G4\": 2}\n",
    "\n",
    "    set_global_seed(cfg.seed)\n",
    "    run_dir = make_run_dir(cfg.out_dir)\n",
    "\n",
    "    # 1) labels\n",
    "    y = make_y(samples_sup, cfg.label_col, cfg.label_map)\n",
    "\n",
    "    # 2) split\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_train_val_test(expression_sup, y, cfg)\n",
    "    save_split_ids(run_dir, X_train, X_val, X_test)\n",
    "\n",
    "    # 3) standardize\n",
    "    X_train_s, X_val_s, X_test_s, scaler = standardize(X_train, X_val, X_test)\n",
    "\n",
    "    # 4) tune\n",
    "    tuner, best_hp = tune_hyperparameters(X_train_s, y_train, X_val_s, y_val, input_dim=X_train_s.shape[1], run_dir=run_dir, cfg=cfg)\n",
    "\n",
    "    # 5) train best\n",
    "    model, ckpt_path = train_best(X_train_s, y_train, X_val_s, y_val, input_dim=X_train_s.shape[1], best_hp=best_hp, run_dir=run_dir, cfg=cfg)\n",
    "\n",
    "    # 6) evaluate\n",
    "    results = evaluate(model, X_test_s, y_test, run_dir)\n",
    "\n",
    "    # 7) save metadata + scaler + best HP\n",
    "    save_run_metadata(run_dir, cfg, best_hp, scaler)\n",
    "\n",
    "    print(\"Saved run to:\", run_dir)\n",
    "    print(\"Best model:\", ckpt_path)\n",
    "    print(\"Test accuracy:\", results[\"test_accuracy\"])\n",
    "    print(\"Macro F1:\", results[\"macro_f1\"])\n",
    "\n",
    "    return results, run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a633a18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 14s]\n",
      "val_accuracy: 0.869918704032898\n",
      "\n",
      "Best val_accuracy So Far: 0.934959352016449\n",
      "Total elapsed time: 00h 39m 00s\n",
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.5332 - loss: 2.3894 - val_accuracy: 0.8049 - val_loss: 1.8378\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6993 - loss: 2.0815 - val_accuracy: 0.8130 - val_loss: 1.7874\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7273 - loss: 2.0125 - val_accuracy: 0.8211 - val_loss: 1.7368\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7517 - loss: 1.8847 - val_accuracy: 0.8618 - val_loss: 1.6946\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7745 - loss: 1.8534 - val_accuracy: 0.8943 - val_loss: 1.6688\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7972 - loss: 1.8083 - val_accuracy: 0.8862 - val_loss: 1.6586\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7885 - loss: 1.7734 - val_accuracy: 0.8862 - val_loss: 1.6494\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8287 - loss: 1.6990 - val_accuracy: 0.8943 - val_loss: 1.6350\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8252 - loss: 1.7037 - val_accuracy: 0.8943 - val_loss: 1.6236\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8234 - loss: 1.7017 - val_accuracy: 0.8943 - val_loss: 1.6197\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8514 - loss: 1.6449 - val_accuracy: 0.8943 - val_loss: 1.6244\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8497 - loss: 1.6482 - val_accuracy: 0.8943 - val_loss: 1.6115\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8427 - loss: 1.6562 - val_accuracy: 0.9024 - val_loss: 1.6016\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8531 - loss: 1.6250 - val_accuracy: 0.9024 - val_loss: 1.6017\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8619 - loss: 1.6197 - val_accuracy: 0.8943 - val_loss: 1.6011\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8951 - loss: 1.5840 - val_accuracy: 0.9024 - val_loss: 1.5916\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8881 - loss: 1.5707 - val_accuracy: 0.9024 - val_loss: 1.5833\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8986 - loss: 1.5522 - val_accuracy: 0.9106 - val_loss: 1.5761\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8986 - loss: 1.5348 - val_accuracy: 0.9106 - val_loss: 1.5716\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9266 - loss: 1.5207 - val_accuracy: 0.9187 - val_loss: 1.5697\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9056 - loss: 1.5335 - val_accuracy: 0.9187 - val_loss: 1.5673\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9178 - loss: 1.5203 - val_accuracy: 0.9187 - val_loss: 1.5721\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 1.5153 - val_accuracy: 0.9187 - val_loss: 1.5741\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9073 - loss: 1.4968 - val_accuracy: 0.9268 - val_loss: 1.5732\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9301 - loss: 1.4870 - val_accuracy: 0.9187 - val_loss: 1.5714\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9248 - loss: 1.4783 - val_accuracy: 0.9024 - val_loss: 1.5660\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9283 - loss: 1.4856 - val_accuracy: 0.9024 - val_loss: 1.5649\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9371 - loss: 1.4676 - val_accuracy: 0.9187 - val_loss: 1.5657\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9406 - loss: 1.4594 - val_accuracy: 0.9106 - val_loss: 1.5583\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9441 - loss: 1.4528 - val_accuracy: 0.9268 - val_loss: 1.5560\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9493 - loss: 1.4342 - val_accuracy: 0.9268 - val_loss: 1.5578\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9423 - loss: 1.4502 - val_accuracy: 0.9268 - val_loss: 1.5527\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9353 - loss: 1.4388 - val_accuracy: 0.9187 - val_loss: 1.5491\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9476 - loss: 1.4194 - val_accuracy: 0.9187 - val_loss: 1.5477\n",
      "Saved run to: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\\20251228_211457\n",
      "Best model: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\\20251228_211457\\best_model.keras\n",
      "Test accuracy: 0.8130081295967102\n",
      "Macro F1: 0.7636139201443289\n"
     ]
    }
   ],
   "source": [
    "#Now we call the main function to run the entire pipeline\n",
    "results, run_dir = main(expression_sup, samples_sup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20251228_211457\\confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "#we can now access the saved metrics to produce evaluation reports and plots\n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20251228_211457\" \n",
    "  \n",
    "\n",
    "# Load metrics\n",
    "with open(os.path.join(run_dir, \"test_metrics.json\"), \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "cm = np.array(metrics[\"confusion_matrix\"])\n",
    "class_names = [\"G2\", \"G3\", \"G4\"]  # must match your label mapping\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, out_path):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm)\n",
    "\n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_yticks(range(len(class_names)))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_confusion_matrix(cm, class_names, os.path.join(run_dir, \"confusion_matrix.png\"))\n",
    "print(\"Saved:\", os.path.join(run_dir, \"confusion_matrix.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
