{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Sequence, Tuple, Union, Dict\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model as keras_load_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "import keras_tuner as kt\n",
    "from dataclasses import dataclass, asdict\n",
    "import random\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from scipy.stats import fisher_exact, chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from statsmodels.stats.contingency_tables import Table2x2\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492f5fe",
   "metadata": {},
   "source": [
    "We load the expression, gene and sample data we saved after the pre-processing we applied in R. We aim to predict tumor grade from the RNAseq data, so we examine potential class imbalance in the tumor grade sample metadata column, and we remove NA values in tumors with unidentified grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e7e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load expression, genes and samples data\n",
    "expression=pd.read_csv(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_expression.csv\",index_col=0)\n",
    "genes=pd.read_csv(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_genes.csv\")\n",
    "samples = pyreadr.read_r(\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_samples.rds\")\n",
    "samples = samples[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b30a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ENSG00000276168.1', 'ENSG00000129824.16', 'ENSG00000133048.13',\n",
      "       'ENSG00000012223.13', 'ENSG00000198695.2'],\n",
      "      dtype='object')\n",
      "                              ENSG00000276168.1  ENSG00000129824.16  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07           8.423027           13.253145   \n",
      "TCGA-DU-7015-01A-11R-2027-07           8.252623            5.532866   \n",
      "\n",
      "                              ENSG00000133048.13  ENSG00000012223.13  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            7.491808            4.879747   \n",
      "TCGA-DU-7015-01A-11R-2027-07            8.707316            5.087127   \n",
      "\n",
      "                              ENSG00000198695.2  ENSG00000228253.1  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          15.950897          12.763416   \n",
      "TCGA-DU-7015-01A-11R-2027-07          16.922914          13.431528   \n",
      "\n",
      "                              ENSG00000198763.3  ENSG00000133110.15  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          17.025877            5.074539   \n",
      "TCGA-DU-7015-01A-11R-2027-07          17.670450            4.085189   \n",
      "\n",
      "                              ENSG00000198899.2  ENSG00000248527.1  ...  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          16.826818          13.863041  ...   \n",
      "TCGA-DU-7015-01A-11R-2027-07          17.706981          14.950704  ...   \n",
      "\n",
      "                              ENSG00000179796.12  ENSG00000240087.3  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            9.234303           4.836707   \n",
      "TCGA-DU-7015-01A-11R-2027-07            9.382020           5.434878   \n",
      "\n",
      "                              ENSG00000157087.20  ENSG00000164128.7  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07           11.285052           5.473512   \n",
      "TCGA-DU-7015-01A-11R-2027-07           12.349215           5.809448   \n",
      "\n",
      "                              ENSG00000170075.9  ENSG00000188783.6  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07          14.468218          11.255899   \n",
      "TCGA-DU-7015-01A-11R-2027-07          13.080774          10.141038   \n",
      "\n",
      "                              ENSG00000112333.12  ENSG00000166819.12  \\\n",
      "TCGA-HT-7468-01A-11R-2027-07            8.641767            6.874675   \n",
      "TCGA-DU-7015-01A-11R-2027-07            8.065001            7.409357   \n",
      "\n",
      "                              ENSG00000116194.13  ENSG00000130988.13  \n",
      "TCGA-HT-7468-01A-11R-2027-07            8.731906            7.238853  \n",
      "TCGA-DU-7015-01A-11R-2027-07            9.466173            7.052062  \n",
      "\n",
      "[2 rows x 2000 columns]\n",
      "                                                   barcode       patient  \\\n",
      "rownames                                                                   \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015   \n",
      "\n",
      "                                        sample shortLetterCode  \\\n",
      "rownames                                                         \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A              TP   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A              TP   \n",
      "\n",
      "                                       definition sample_submitter_id  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07  Primary solid Tumor    TCGA-HT-7468-01A   \n",
      "TCGA-DU-7015-01A-11R-2027-07  Primary solid Tumor    TCGA-DU-7015-01A   \n",
      "\n",
      "                              intermediate_dimension tumor_descriptor  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07                     0.7          Primary   \n",
      "TCGA-DU-7015-01A-11R-2027-07                     1.0          Primary   \n",
      "\n",
      "                                                 sample_id  \\\n",
      "rownames                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07  TCGA-HT-7468-01A-11R-2027-07   \n",
      "TCGA-DU-7015-01A-11R-2027-07  TCGA-DU-7015-01A-11R-2027-07   \n",
      "\n",
      "                                             pathology_report_uuid  ...  \\\n",
      "rownames                                                            ...   \n",
      "TCGA-HT-7468-01A-11R-2027-07  f56fcc2c-db3d-4ae5-b8dc-975b98fb4675  ...   \n",
      "TCGA-DU-7015-01A-11R-2027-07  15dbad7b-e2ae-42b0-92a1-5ccfc3090c2d  ...   \n",
      "\n",
      "                             paper_IDH.specific.RNA.Expression.Cluster  \\\n",
      "rownames                                                                 \n",
      "TCGA-HT-7468-01A-11R-2027-07                                 IDHmut-R1   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                 IDHmut-R3   \n",
      "\n",
      "                              paper_Pan.Glioma.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                 \n",
      "TCGA-HT-7468-01A-11R-2027-07                                      LGm3   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                      LGm2   \n",
      "\n",
      "                             paper_IDH.specific.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                  \n",
      "TCGA-HT-7468-01A-11R-2027-07                                  IDHmut-K3   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                  IDHmut-K2   \n",
      "\n",
      "                             paper_Supervised.DNA.Methylation.Cluster  \\\n",
      "rownames                                                                \n",
      "TCGA-HT-7468-01A-11R-2027-07                                    Codel   \n",
      "TCGA-DU-7015-01A-11R-2027-07                              G-CIMP-high   \n",
      "\n",
      "                              paper_Random.Forest.Sturm.Cluster  \\\n",
      "rownames                                                          \n",
      "TCGA-HT-7468-01A-11R-2027-07                                IDH   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                IDH   \n",
      "\n",
      "                             paper_RPPA.cluster  \\\n",
      "rownames                                          \n",
      "TCGA-HT-7468-01A-11R-2027-07                 K2   \n",
      "TCGA-DU-7015-01A-11R-2027-07                 K2   \n",
      "\n",
      "                             paper_Telomere.length.estimate.in.blood.normal..Kb.  \\\n",
      "rownames                                                                           \n",
      "TCGA-HT-7468-01A-11R-2027-07                                             5.4533    \n",
      "TCGA-DU-7015-01A-11R-2027-07                                                NaN    \n",
      "\n",
      "                              paper_Telomere.length.estimate.in.tumor..Kb.  \\\n",
      "rownames                                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07                                        2.5218   \n",
      "TCGA-DU-7015-01A-11R-2027-07                                           NaN   \n",
      "\n",
      "                             tumor_type method_of_diagnosis  \n",
      "rownames                                                     \n",
      "TCGA-HT-7468-01A-11R-2027-07        LGG                 NaN  \n",
      "TCGA-DU-7015-01A-11R-2027-07        LGG                 NaN  \n",
      "\n",
      "[2 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "#check what the expression, genes and samples data look like\n",
    "print(expression.columns[:5])\n",
    "print(expression.head(2))\n",
    "print(samples.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cbcc870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(925, 114)\n",
      "tumor_grade\n",
      "G4    391\n",
      "G3    216\n",
      "G2    211\n",
      "Name: count, dtype: int64\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "#explore the samples metadata\n",
    "print(samples.shape)\n",
    "# list of column names\n",
    "samples.columns.tolist()\n",
    "\n",
    "#check for potential class imbalance in tumor grade\n",
    "print(samples[\"tumor_grade\"].value_counts())\n",
    "\n",
    "#count how many NA values are in the tumor grade column\n",
    "print(samples[\"tumor_grade\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b7695a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we exclude samples with NA tumor grade\n",
    "samples_all = samples.copy() #keep original samples dataframe\n",
    "expression_all = expression.copy() #keep original expression dataframe\n",
    "\n",
    "samples_sup = samples_all.dropna(subset=[\"tumor_grade\"])\n",
    "expression_sup = expression_all.loc[samples_sup.index]\n",
    "\n",
    "assert expression_sup.shape[0] == samples_sup.shape[0], \"Mismatch in number of samples between expression and samples dataframes after dropping NA tumor grades.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e09d5ad",
   "metadata": {},
   "source": [
    "We configure the model and ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e796cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    out_dir: str = \"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\"\n",
    "    seed: int = 42\n",
    "\n",
    "    # labels\n",
    "    label_col: str = \"tumor_grade\"\n",
    "    label_map: dict = None  # set in main if None\n",
    "\n",
    "    # splits\n",
    "    test_size: float = 0.15\n",
    "    n_folds: int = 9  # 9-fold CV on train+val portion\n",
    "\n",
    "    # training/tuning\n",
    "    max_epochs: int = 100\n",
    "    early_stop_patience: int = 5\n",
    "\n",
    "    # tuner\n",
    "    hyperband_factor: int = 3\n",
    "    objective: str = \"val_accuracy\"\n",
    "\n",
    "def set_global_seed(seed: int) -> None:\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # makes TF ops more deterministic when possible\n",
    "    try:\n",
    "        tf.config.experimental.enable_op_determinism()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def make_run_dir(base_dir: str) -> str:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(base_dir, ts)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d10a2",
   "metadata": {},
   "source": [
    "We assign the classes. Grade II tumors will be 0, grade III will be 1 and grade IV will be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "52b72236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_y(samples_sup: pd.DataFrame, label_col: str, label_map: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert tumor grade strings to integer classes.\n",
    "    Example mapping: {\"G2\":0, \"G3\":1, \"G4\":2}\n",
    "    \"\"\"\n",
    "    y = samples_sup[label_col].astype(str).map(label_map)\n",
    "    if y.isna().any():\n",
    "        bad = samples_sup.loc[y.isna(), label_col].unique()\n",
    "        raise ValueError(f\"Found unmapped labels: {bad}\")\n",
    "    return y.astype(int).to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a5fbb",
   "metadata": {},
   "source": [
    "We construct our  splits: we will have a hold-out test set, and run a 9-fold cross-validation on the rest of the data. In the cross-validation we include training and validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6420581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_holdout_test(X: pd.DataFrame, y: np.ndarray, cfg: Config):\n",
    "    \"\"\"\n",
    "    Hold out ONE stratified test set.\n",
    "    Remaining data is used for 9-fold CV (train/val folds).\n",
    "    \"\"\"\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=cfg.test_size,\n",
    "        random_state=cfg.seed,\n",
    "        stratify=y\n",
    "    )\n",
    "    return X_trainval, X_test, y_trainval, y_test\n",
    "\n",
    "def save_test_ids(run_dir: str, X_test: pd.DataFrame) -> None:\n",
    "    pd.Index(X_test.index).to_series().to_csv(os.path.join(run_dir, \"test_ids.csv\"), index=False)\n",
    "\n",
    "def save_fold_ids(run_dir: str, fold: int, X_train: pd.DataFrame, X_val: pd.DataFrame) -> None:\n",
    "    fold_dir = os.path.join(run_dir, f\"fold_{fold:02d}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "    pd.Index(X_train.index).to_series().to_csv(os.path.join(fold_dir, \"train_ids.csv\"), index=False)\n",
    "    pd.Index(X_val.index).to_series().to_csv(os.path.join(fold_dir, \"val_ids.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d257ba",
   "metadata": {},
   "source": [
    "We standardize the data, fitting on test data only to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "68c663e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_train_val(X_train: pd.DataFrame, X_val: pd.DataFrame):\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_s = scaler.fit_transform(X_train).astype(np.float32)\n",
    "    X_val_s = scaler.transform(X_val).astype(np.float32)\n",
    "    return X_train_s, X_val_s, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97070e",
   "metadata": {},
   "source": [
    "We build our multi-layer perceptron model (MLP) with ReLU activation function in the hidden layers and softmax in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4b49462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp: kt.HyperParameters, input_dim: int, num_classes: int = 3) -> keras.Model:\n",
    "    \"\"\"\n",
    "    MLP with tunable depth and two architecture modes:\n",
    "      1) Free: each layer can have its own units (picked from a grid)\n",
    "      2) Pyramid: pick a base width; each next layer is half the previous (e.g. 32 -> 16 -> 8)\n",
    "    \"\"\"\n",
    "\n",
    "    # batch size is tuned by your HyperbandWithBatchSize tuner\n",
    "    hp.Choice(\"batch_size\", [16, 32, 64, 128])\n",
    "\n",
    "    # --- depth ---\n",
    "    n_layers = hp.Int(\"n_layers\", 2, 6)\n",
    "\n",
    "    # --- regularization / optimizer ---\n",
    "    l2_strength = hp.Choice(\"l2\", [0.0, 1e-5, 1e-4, 1e-3])\n",
    "    lr = hp.Choice(\"lr\", [1e-4, 3e-4, 1e-3, 3e-3])\n",
    "\n",
    "    # --- dropout (global) ---\n",
    "    dropout = hp.Float(\"dropout\", 0.1, 0.6, step=0.1)\n",
    "\n",
    "    # --- units search space ---\n",
    "    units_grid = [8, 16, 32, 64, 128, 256]\n",
    "\n",
    "    # --- architecture mode ---\n",
    "    arch_mode = hp.Choice(\"arch_mode\", [\"free\", \"pyramid_half\"])\n",
    "\n",
    "    # Decide units per layer\n",
    "    layer_units = []\n",
    "\n",
    "    if arch_mode == \"free\":\n",
    "        for i in range(n_layers):\n",
    "            u = hp.Choice(f\"units_l{i+1}\", units_grid)\n",
    "            layer_units.append(u)\n",
    "\n",
    "    elif arch_mode == \"pyramid_half\":\n",
    "        base_units = hp.Choice(\"base_units\", units_grid)\n",
    "        min_units = hp.Choice(\"min_units\", [8, 16])\n",
    "\n",
    "        u = base_units\n",
    "        for i in range(n_layers):\n",
    "            layer_units.append(max(u, min_units))\n",
    "            u = u // 2\n",
    "\n",
    "    # --- build network ---\n",
    "    inputs = keras.Input(shape=(input_dim,), name=\"expression\")\n",
    "    x = inputs\n",
    "\n",
    "    for i, u in enumerate(layer_units, start=1):\n",
    "        x = layers.Dense(\n",
    "            units=u,\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=regularizers.l2(l2_strength),\n",
    "            name=f\"dense_{i}\",\n",
    "        )(x)\n",
    "\n",
    "        if dropout and dropout > 0:\n",
    "            x = layers.Dropout(dropout, name=f\"dropout_{i}\")(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"MLP_grade\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f1fa8",
   "metadata": {},
   "source": [
    "We tune the hyper-paramaters to choose the best model and avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aea6b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperbandWithBatchSize(kt.Hyperband):\n",
    "    \"\"\"Hyperband tuner that automatically uses hp['batch_size'] when fitting.\"\"\"\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        hp = trial.hyperparameters\n",
    "        kwargs[\"batch_size\"] = hp.get(\"batch_size\")\n",
    "        return super().run_trial(trial, *args, **kwargs)\n",
    "\n",
    "def tune_hyperparameters(X_train_s, y_train, X_val_s, y_val, input_dim: int, run_dir: str, cfg: Config):\n",
    "    tuner_dir = os.path.join(run_dir, \"tuner\")\n",
    "    os.makedirs(tuner_dir, exist_ok=True)\n",
    "\n",
    "    tuner = HyperbandWithBatchSize(\n",
    "        hypermodel=lambda hp: build_model(hp, input_dim=input_dim, num_classes=3),\n",
    "        objective=kt.Objective(cfg.objective, direction=\"max\"),\n",
    "        max_epochs=cfg.max_epochs,\n",
    "        factor=cfg.hyperband_factor,\n",
    "        directory=tuner_dir,\n",
    "        project_name=\"grade_mlp\"\n",
    "    )\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        patience=cfg.early_stop_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        X_train_s, y_train,\n",
    "        validation_data=(X_val_s, y_val),\n",
    "        epochs=cfg.max_epochs,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "    return tuner, best_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6801fd97",
   "metadata": {},
   "source": [
    "We choose the best model to train on which we add weights to account for imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d6e18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_weight(y_train: np.ndarray) -> dict:\n",
    "    classes = np.unique(y_train)\n",
    "    weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "    return {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "\n",
    "def train_best(X_train_s, y_train, X_val_s, y_val, input_dim: int, best_hp, run_dir: str, cfg: Config):\n",
    "    model = build_model(best_hp, input_dim=input_dim, num_classes=3)\n",
    "\n",
    "    ckpt_path = os.path.join(run_dir, \"best_model.keras\")\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        patience=cfg.early_stop_patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=ckpt_path,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    # class weights (computed on this fold's training labels)\n",
    "    class_weight = make_class_weight(y_train)\n",
    "    print(\"Class weight:\", class_weight)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_s, y_train,\n",
    "        validation_data=(X_val_s, y_val),\n",
    "        epochs=cfg.max_epochs,\n",
    "        batch_size=best_hp.get(\"batch_size\"),\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=1,\n",
    "        class_weight=class_weight  # NEW\n",
    "    )\n",
    "\n",
    "    with open(os.path.join(run_dir, \"history.json\"), \"w\") as f:\n",
    "        json.dump(history.history, f, indent=2)\n",
    "\n",
    "    return model, ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef7714",
   "metadata": {},
   "source": [
    "We evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cbaed84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: keras.Model, X_eval_s, y_eval, run_dir: str, prefix: str = \"eval\"):\n",
    "    eval_loss, eval_acc = model.evaluate(X_eval_s, y_eval, verbose=0)\n",
    "\n",
    "    probs = model.predict(X_eval_s, verbose=0)\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "\n",
    "    report = classification_report(y_eval, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_eval, y_pred).tolist()\n",
    "    macro_f1 = float(f1_score(y_eval, y_pred, average=\"macro\"))\n",
    "\n",
    "    results = {\n",
    "        \"loss\": float(eval_loss),\n",
    "        \"accuracy\": float(eval_acc),\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": cm\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(run_dir, f\"{prefix}_metrics.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a6d782",
   "metadata": {},
   "source": [
    "We save all the run metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f9916f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_run_metadata(run_dir: str, cfg: Config, best_hp, scaler):\n",
    "    with open(os.path.join(run_dir, \"config.json\"), \"w\") as f:\n",
    "        json.dump(asdict(cfg), f, indent=2)\n",
    "\n",
    "    with open(os.path.join(run_dir, \"best_hyperparameters.json\"), \"w\") as f:\n",
    "        json.dump(best_hp.values, f, indent=2)\n",
    "\n",
    "    joblib.dump(scaler, os.path.join(run_dir, \"scaler.joblib\"))\n",
    "\n",
    "    versions = {\n",
    "        \"python\": f\"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}\",\n",
    "        \"numpy\": np.__version__,\n",
    "        \"pandas\": pd.__version__,\n",
    "        \"tensorflow\": tf.__version__,\n",
    "        \"keras_tuner\": kt.__version__\n",
    "    }\n",
    "    with open(os.path.join(run_dir, \"versions.json\"), \"w\") as f:\n",
    "        json.dump(versions, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb81ee",
   "metadata": {},
   "source": [
    "We plot Evaluation Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c2ffa5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def evaluate_and_save_plots(\n",
    "    model,\n",
    "    X_eval_s: np.ndarray,\n",
    "    y_eval: np.ndarray,\n",
    "    out_dir: str,\n",
    "    class_names=(\"G2\", \"G3\", \"G4\"),\n",
    "    prefix: str = \"test\",\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    n_classes = len(class_names)\n",
    "\n",
    "    # predictions \n",
    "    eval_loss, eval_acc = model.evaluate(X_eval_s, y_eval, verbose=0)\n",
    "    probs = model.predict(X_eval_s, verbose=0)          # (n, C)\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "\n",
    "    # metrics \n",
    "    report = classification_report(y_eval, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "    macro_f1 = float(f1_score(y_eval, y_pred, average=\"macro\"))\n",
    "\n",
    "    results = {\n",
    "        \"loss\": float(eval_loss),\n",
    "        \"accuracy\": float(eval_acc),\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(out_dir, f\"{prefix}_metrics.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    \n",
    "    # 1) Confusion matrix (raw)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm)\n",
    "    ax.set_xticks(range(n_classes))\n",
    "    ax.set_yticks(range(n_classes))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(class_names)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix ({prefix})\")\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{prefix}_confusion_matrix.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "    # 2) Confusion matrix (row-normalized)\n",
    "    \n",
    "    cm_norm = cm / np.clip(cm.sum(axis=1, keepdims=True), 1, None)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm_norm)\n",
    "    ax.set_xticks(range(n_classes))\n",
    "    ax.set_yticks(range(n_classes))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(class_names)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(f\"Confusion Matrix Normalized ({prefix})\")\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            ax.text(j, i, f\"{cm_norm[i, j]:.2f}\", ha=\"center\", va=\"center\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{prefix}_cm_normalized.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "    # 3) Per-class precision/recall/F1 bar plot\n",
    "    \n",
    "    rows = []\n",
    "    for i, name in enumerate(class_names):\n",
    "        d = report.get(str(i), None)\n",
    "        if d is None:\n",
    "            rows.append([name, np.nan, np.nan, np.nan])\n",
    "        else:\n",
    "            rows.append([name, d[\"precision\"], d[\"recall\"], d[\"f1-score\"]])\n",
    "\n",
    "    rows = np.array(rows, dtype=float, copy=False) if False else rows  # no-op; keeps notebook happy\n",
    "\n",
    "    precision = [r[1] for r in rows]\n",
    "    recall    = [r[2] for r in rows]\n",
    "    f1s       = [r[3] for r in rows]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.arange(n_classes)\n",
    "    ax.bar(x - 0.2, precision, width=0.2, label=\"precision\")\n",
    "    ax.bar(x,       recall,    width=0.2, label=\"recall\")\n",
    "    ax.bar(x + 0.2, f1s,       width=0.2, label=\"f1\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(class_names)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_title(f\"Per-class metrics ({prefix})\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{prefix}_per_class_metrics.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "   \n",
    "    # 4) ROC curves (one-vs-rest)\n",
    "    \n",
    "    Y = label_binarize(y_eval, classes=list(range(n_classes)))  # (n, C)\n",
    "\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for c in range(n_classes):\n",
    "        fpr[c], tpr[c], _ = roc_curve(Y[:, c], probs[:, c])\n",
    "        roc_auc[c] = auc(fpr[c], tpr[c])\n",
    "\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y.ravel(), probs.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for c, name in enumerate(class_names):\n",
    "        ax.plot(fpr[c], tpr[c], label=f\"{name} (AUC={roc_auc[c]:.3f})\")\n",
    "    ax.plot(fpr[\"micro\"], tpr[\"micro\"], linestyle=\"--\", label=f\"micro (AUC={roc_auc['micro']:.3f})\")\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\":\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(f\"ROC (one-vs-rest) ({prefix})\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{prefix}_roc_curves.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "    # 5) Precision–Recall curves (one-vs-rest)\n",
    "    \n",
    "    pr, re, ap = {}, {}, {}\n",
    "    for c in range(n_classes):\n",
    "        pr[c], re[c], _ = precision_recall_curve(Y[:, c], probs[:, c])\n",
    "        ap[c] = average_precision_score(Y[:, c], probs[:, c])\n",
    "\n",
    "    pr_micro, re_micro, _ = precision_recall_curve(Y.ravel(), probs.ravel())\n",
    "    ap_micro = average_precision_score(Y, probs, average=\"micro\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for c, name in enumerate(class_names):\n",
    "        ax.plot(re[c], pr[c], label=f\"{name} (AP={ap[c]:.3f})\")\n",
    "    ax.plot(re_micro, pr_micro, linestyle=\"--\", label=f\"micro (AP={ap_micro:.3f})\")\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    ax.set_title(f\"Precision–Recall (one-vs-rest) ({prefix})\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{prefix}_pr_curves.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b6ba1",
   "metadata": {},
   "source": [
    "Permutation Feature Importance (not included in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94ebc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_classes(model, X_s: np.ndarray, batch_size: int = 256) -> np.ndarray:\n",
    "    probs = model.predict(X_s, verbose=0, batch_size=batch_size)\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "def _compute_metrics(y_true, y_pred, n_classes: int):\n",
    "    out = {}\n",
    "    out[\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    out[\"macro_f1\"] = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    out[\"per_class_f1\"] = f1_score(y_true, y_pred, average=None, labels=list(range(n_classes)))\n",
    "    out[\"per_class_recall\"] = recall_score(y_true, y_pred, average=None, labels=list(range(n_classes)))\n",
    "    return out\n",
    "\n",
    "def permutation_importance_multiclass(\n",
    "    model,\n",
    "    X_s: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names,\n",
    "    out_dir: str,\n",
    "    class_names=(\"G2\", \"G3\", \"G4\"),\n",
    "    n_repeats: int = 50,\n",
    "    top_k: int = 10,\n",
    "    max_features: int | None = 400,     \n",
    "    batch_size_pred: int = 256,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Permutation importance on a fixed eval set (e.g. held-out test).\n",
    "\n",
    "    Global metrics:\n",
    "      - accuracy\n",
    "      - macro_f1\n",
    "\n",
    "    Per-class metrics:\n",
    "      - f1 per class\n",
    "      - recall per class (acts like per-class accuracy)\n",
    "\n",
    "    Saves:\n",
    "      - CSVs with mean +/- std drops\n",
    "      - Top-K bar plots for each metric\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    X_s = np.asarray(X_s)\n",
    "    y = np.asarray(y).astype(int)\n",
    "    n_classes = len(class_names)\n",
    "    n_samples, n_features = X_s.shape\n",
    "\n",
    "    feature_names = np.array(list(feature_names), dtype=object)\n",
    "    if feature_names.shape[0] != n_features:\n",
    "        raise ValueError(\"feature_names length does not match X_s number of columns.\")\n",
    "\n",
    "    # choose features to evaluate \n",
    "    if (max_features is not None) and (n_features > max_features):\n",
    "        # pick highest-variance features \n",
    "        variances = X_s.var(axis=0)\n",
    "        feat_idx = np.argsort(-variances)[:max_features]\n",
    "        feat_idx = np.sort(feat_idx)\n",
    "        note = f\"NOTE: computed permutation importance on top-{max_features} variance genes (out of {n_features}).\"\n",
    "    else:\n",
    "        feat_idx = np.arange(n_features)\n",
    "        note = f\"NOTE: computed permutation importance on ALL genes ({n_features}).\"\n",
    "\n",
    "    with open(os.path.join(out_dir, \"perm_importance_NOTE.txt\"), \"w\") as f:\n",
    "        f.write(note + \"\\n\")\n",
    "    print(note)\n",
    "\n",
    "    # baseline predictions/metrics \n",
    "    y_pred_base = _predict_classes(model, X_s, batch_size=batch_size_pred)\n",
    "    base = _compute_metrics(y, y_pred_base, n_classes)\n",
    "\n",
    "    # storage: drops (baseline - permuted) so higher drop means more important\n",
    "    drops_acc = np.zeros((len(feat_idx), n_repeats), dtype=float)\n",
    "    drops_macro_f1 = np.zeros((len(feat_idx), n_repeats), dtype=float)\n",
    "    drops_f1 = np.zeros((len(feat_idx), n_repeats, n_classes), dtype=float)\n",
    "    drops_recall = np.zeros((len(feat_idx), n_repeats, n_classes), dtype=float)\n",
    "\n",
    "    X_work = X_s.copy()  # will permute columns in-place, then restore\n",
    "\n",
    "    for fi_pos, j in enumerate(feat_idx):\n",
    "        original_col = X_work[:, j].copy()\n",
    "\n",
    "        for r in range(n_repeats):\n",
    "            perm = rng.permutation(n_samples)\n",
    "            X_work[:, j] = original_col[perm]\n",
    "\n",
    "            y_pred_perm = _predict_classes(model, X_work, batch_size=batch_size_pred)\n",
    "            m = _compute_metrics(y, y_pred_perm, n_classes)\n",
    "\n",
    "            drops_acc[fi_pos, r] = base[\"accuracy\"] - m[\"accuracy\"]\n",
    "            drops_macro_f1[fi_pos, r] = base[\"macro_f1\"] - m[\"macro_f1\"]\n",
    "            drops_f1[fi_pos, r, :] = base[\"per_class_f1\"] - m[\"per_class_f1\"]\n",
    "            drops_recall[fi_pos, r, :] = base[\"per_class_recall\"] - m[\"per_class_recall\"]\n",
    "\n",
    "        # restore column\n",
    "        X_work[:, j] = original_col\n",
    "\n",
    "    # summarize \n",
    "    names_sel = feature_names[feat_idx]\n",
    "\n",
    "    df_global = pd.DataFrame({\n",
    "    \"feature\": names_sel,\n",
    "    \"mean_ig\":     ig_sel.mean(axis=0),\n",
    "    \"std_ig\":      ig_sel.std(axis=0),\n",
    "    \"mean_abs_ig\": abs_ig_sel.mean(axis=0),\n",
    "    \"std_abs_ig\":  abs_ig_sel.std(axis=0),\n",
    "    }).sort_values(\"mean_abs_ig\", ascending=False)\n",
    "\n",
    "\n",
    "    # per-class tables\n",
    "    per_class_rows = []\n",
    "    for c, cname in enumerate(class_names):\n",
    "        tmp = pd.DataFrame({\n",
    "            \"feature\": names_sel,\n",
    "            f\"drop_f1_{cname}_mean\": drops_f1[:, :, c].mean(axis=1),\n",
    "            f\"drop_f1_{cname}_std\": drops_f1[:, :, c].std(axis=1),\n",
    "            f\"drop_recall_{cname}_mean\": drops_recall[:, :, c].mean(axis=1),\n",
    "            f\"drop_recall_{cname}_std\": drops_recall[:, :, c].std(axis=1),\n",
    "        })\n",
    "        per_class_rows.append(tmp)\n",
    "\n",
    "    df_per_class = per_class_rows[0]\n",
    "    for k in per_class_rows[1:]:\n",
    "        df_per_class = df_per_class.merge(k, on=\"feature\")\n",
    "\n",
    "    # save csvs\n",
    "    df_global.to_csv(os.path.join(out_dir, \"perm_importance_global.csv\"), index=False)\n",
    "    df_per_class.to_csv(os.path.join(out_dir, \"perm_importance_per_class.csv\"), index=False)\n",
    "\n",
    "    # plotting helpers \n",
    "    def _bar_topk(df, score_col, std_col, title, filename, top_k=10):\n",
    "        d = df.sort_values(score_col, ascending=False).head(top_k).copy()\n",
    "        d = d.iloc[::-1]  # so top is at top in barh\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 0.4*len(d) + 2.5))\n",
    "        ax.barh(d[\"feature\"].astype(str), d[score_col].to_numpy(), xerr=d[std_col].to_numpy())\n",
    "        ax.set_xlabel(\"Performance drop after permutation\")\n",
    "        ax.set_title(title)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(out_dir, filename), dpi=200)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # global plots\n",
    "    _bar_topk(\n",
    "        df_global, \"drop_accuracy_mean\", \"drop_accuracy_std\",\n",
    "        title=f\"Permutation importance (Global Accuracy) — Top {top_k}\",\n",
    "        filename=f\"perm_top{top_k}_global_accuracy.png\",\n",
    "        top_k=top_k\n",
    "    )\n",
    "    _bar_topk(\n",
    "        df_global, \"drop_macro_f1_mean\", \"drop_macro_f1_std\",\n",
    "        title=f\"Permutation importance (Global Macro-F1) — Top {top_k}\",\n",
    "        filename=f\"perm_top{top_k}_global_macro_f1.png\",\n",
    "        top_k=top_k\n",
    "    )\n",
    "\n",
    "    # per-class plots (F1 + Recall)\n",
    "    for cname in class_names:\n",
    "        _bar_topk(\n",
    "            df_per_class,\n",
    "            f\"drop_f1_{cname}_mean\", f\"drop_f1_{cname}_std\",\n",
    "            title=f\"Permutation importance (Per-class F1: {cname}) — Top {top_k}\",\n",
    "            filename=f\"perm_top{top_k}_f1_{cname}.png\",\n",
    "            top_k=top_k\n",
    "        )\n",
    "        _bar_topk(\n",
    "            df_per_class,\n",
    "            f\"drop_recall_{cname}_mean\", f\"drop_recall_{cname}_std\",\n",
    "            title=f\"Permutation importance (Per-class Recall: {cname}) — Top {top_k}\",\n",
    "            filename=f\"perm_top{top_k}_recall_{cname}.png\",\n",
    "            top_k=top_k\n",
    "        )\n",
    "\n",
    "    # return dataframes + baseline metrics for reporting\n",
    "    baseline_summary = {\n",
    "        \"baseline_accuracy\": float(base[\"accuracy\"]),\n",
    "        \"baseline_macro_f1\": float(base[\"macro_f1\"]),\n",
    "        \"baseline_per_class_f1\": {class_names[i]: float(base[\"per_class_f1\"][i]) for i in range(n_classes)},\n",
    "        \"baseline_per_class_recall\": {class_names[i]: float(base[\"per_class_recall\"][i]) for i in range(n_classes)},\n",
    "        \"note\": note,\n",
    "        \"n_repeats\": int(n_repeats),\n",
    "        \"evaluated_features\": int(len(feat_idx)),\n",
    "    }\n",
    "    with open(os.path.join(out_dir, \"perm_importance_baseline.json\"), \"w\") as f:\n",
    "        import json\n",
    "        json.dump(baseline_summary, f, indent=2)\n",
    "\n",
    "    print(\"Saved permutation importance CSVs + plots to:\", out_dir)\n",
    "    return df_global, df_per_class, baseline_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3c5db",
   "metadata": {},
   "source": [
    "Main run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75397e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(expression_sup: pd.DataFrame, samples_sup: pd.DataFrame):\n",
    "    cfg = Config()\n",
    "    if cfg.label_map is None:\n",
    "        cfg.label_map = {\"G2\": 0, \"G3\": 1, \"G4\": 2}\n",
    "\n",
    "    set_global_seed(cfg.seed)\n",
    "    run_dir = make_run_dir(cfg.out_dir)\n",
    "\n",
    "    #labels\n",
    "    y = make_y(samples_sup, cfg.label_col, cfg.label_map)\n",
    "\n",
    "    #hold-out test\n",
    "    X_trainval, X_test, y_trainval, y_test = split_holdout_test(expression_sup, y, cfg)\n",
    "    save_test_ids(run_dir, X_test)\n",
    "\n",
    "    #9-fold CV on trainval\n",
    "    skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
    "\n",
    "    cv_results = []\n",
    "    best_hp = None\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_trainval, y_trainval), start=1):\n",
    "        fold_dir = os.path.join(run_dir, f\"fold_{fold:02d}\")\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "        X_tr = X_trainval.iloc[tr_idx]\n",
    "        X_va = X_trainval.iloc[va_idx]\n",
    "        y_tr = y_trainval[tr_idx]\n",
    "        y_va = y_trainval[va_idx]\n",
    "\n",
    "        save_fold_ids(run_dir, fold, X_tr, X_va)\n",
    "\n",
    "        # standardize per-fold \n",
    "        X_tr_s, X_va_s, _scaler_fold = standardize_train_val(X_tr, X_va)\n",
    "\n",
    "        # tune once and reuse HP for all folds to save time\n",
    "        if best_hp is None:\n",
    "            tuner, best_hp = tune_hyperparameters(\n",
    "                X_tr_s, y_tr,\n",
    "                X_va_s, y_va,\n",
    "                input_dim=X_tr_s.shape[1],\n",
    "                run_dir=fold_dir,\n",
    "                cfg=cfg\n",
    "            )\n",
    "\n",
    "            with open(os.path.join(run_dir, \"best_hyperparameters.json\"), \"w\") as f:\n",
    "                json.dump(best_hp.values, f, indent=2)\n",
    "\n",
    "        # train best HP on this fold\n",
    "        model, ckpt_path = train_best(\n",
    "            X_tr_s, y_tr,\n",
    "            X_va_s, y_va,\n",
    "            input_dim=X_tr_s.shape[1],\n",
    "            best_hp=best_hp,\n",
    "            run_dir=fold_dir,\n",
    "            cfg=cfg\n",
    "        )\n",
    "\n",
    "        # evaluate on fold validation\n",
    "        fold_metrics = evaluate(model, X_va_s, y_va, fold_dir, prefix=\"val\")\n",
    "\n",
    "        cv_results.append({\n",
    "            \"fold\": fold,\n",
    "            \"val_accuracy\": fold_metrics[\"accuracy\"],\n",
    "            \"val_macro_f1\": fold_metrics[\"macro_f1\"],\n",
    "            \"model_path\": ckpt_path\n",
    "        })\n",
    "\n",
    "    with open(os.path.join(run_dir, \"cv_results.json\"), \"w\") as f:\n",
    "        json.dump(cv_results, f, indent=2)\n",
    "\n",
    "    #final training on all trainval with a small internal val split for early stopping\n",
    "    X_tr_final, X_va_final, y_tr_final, y_va_final = train_test_split(\n",
    "        X_trainval, y_trainval,\n",
    "        test_size=0.15,\n",
    "        random_state=cfg.seed,\n",
    "        stratify=y_trainval\n",
    "    )\n",
    "\n",
    "    scaler_final = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_tr_final_s = scaler_final.fit_transform(X_tr_final).astype(np.float32)\n",
    "    X_va_final_s = scaler_final.transform(X_va_final).astype(np.float32)\n",
    "    X_test_s = scaler_final.transform(X_test).astype(np.float32)\n",
    "\n",
    "    final_dir = os.path.join(run_dir, \"final\")\n",
    "    os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "    model_final, ckpt_path_final = train_best(\n",
    "        X_tr_final_s, y_tr_final,\n",
    "        X_va_final_s, y_va_final,\n",
    "        input_dim=X_tr_final_s.shape[1],\n",
    "        best_hp=best_hp,\n",
    "        run_dir=final_dir,\n",
    "        cfg=cfg\n",
    "    )\n",
    "\n",
    "    #permutation feature importance on final model (not reported)\n",
    "    df_global, df_per_class, baseline_pi = permutation_importance_multiclass(\n",
    "    model=model_final,\n",
    "    X_s=X_test_s,\n",
    "    y=y_test,\n",
    "    feature_names=X_test.columns,      # gene IDs in correct order\n",
    "    out_dir=final_dir,                 # save\n",
    "    class_names=(\"G2\", \"G3\", \"G4\"),\n",
    "    n_repeats=5,\n",
    "    top_k=10,\n",
    "    max_features=200,                  \n",
    "    batch_size_pred=256,\n",
    "    seed=cfg.seed,\n",
    ")\n",
    "\n",
    "    #evaluate once on held-out test\n",
    "    class_names = [\"G2\", \"G3\", \"G4\"]\n",
    "    test_results = evaluate_and_save_plots(\n",
    "    model_final,\n",
    "    X_test_s,\n",
    "    y_test,\n",
    "    out_dir=final_dir,     \n",
    "    class_names=class_names,\n",
    "    prefix=\"test\",\n",
    "    )\n",
    "    \n",
    "    #save metadata + final scaler\n",
    "    save_run_metadata(final_dir, cfg, best_hp, scaler_final)\n",
    "\n",
    "    # print summary\n",
    "    val_accs = [r[\"val_accuracy\"] for r in cv_results]\n",
    "    val_f1s = [r[\"val_macro_f1\"] for r in cv_results]\n",
    "\n",
    "    print(\"Saved run to:\", run_dir)\n",
    "    print(\"Final model:\", ckpt_path_final)\n",
    "    print(f\"CV val accuracy: mean={np.mean(val_accs):.4f} std={np.std(val_accs):.4f}\")\n",
    "    print(f\"CV val macro F1: mean={np.mean(val_f1s):.4f} std={np.std(val_f1s):.4f}\")\n",
    "    print(\"Test accuracy:\", test_results[\"accuracy\"])\n",
    "    print(\"Test macro F1:\", test_results[\"macro_f1\"])\n",
    "\n",
    "    return test_results, run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a633a18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 09s]\n",
      "val_accuracy: 0.7051281929016113\n",
      "\n",
      "Best val_accuracy So Far: 0.8589743375778198\n",
      "Total elapsed time: 00h 23m 41s\n",
      "Class weight: {0: 1.2935010482180294, 1: 1.261758691206544, 2: 0.6971751412429379}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7293 - loss: 0.9049 - val_accuracy: 0.7179 - val_loss: 0.5916\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.4919 - val_accuracy: 0.7949 - val_loss: 0.4891\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8460 - loss: 0.4206 - val_accuracy: 0.7564 - val_loss: 0.5025\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3406 - val_accuracy: 0.7436 - val_loss: 0.4952\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2731 - val_accuracy: 0.7821 - val_loss: 0.6887\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9173 - loss: 0.2539 - val_accuracy: 0.7692 - val_loss: 0.6804\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9190 - loss: 0.2384 - val_accuracy: 0.7821 - val_loss: 0.5575\n",
      "Class weight: {0: 1.2935010482180294, 1: 1.261758691206544, 2: 0.6971751412429379}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7504 - loss: 0.7580 - val_accuracy: 0.7821 - val_loss: 0.4500\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.5138 - val_accuracy: 0.8462 - val_loss: 0.3740\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.3946 - val_accuracy: 0.8205 - val_loss: 0.4217\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8622 - loss: 0.3693 - val_accuracy: 0.8205 - val_loss: 0.4444\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.3136 - val_accuracy: 0.8462 - val_loss: 0.4682\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.2951 - val_accuracy: 0.8462 - val_loss: 0.4109\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8963 - loss: 0.3021 - val_accuracy: 0.8590 - val_loss: 0.4186\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8947 - loss: 0.2692 - val_accuracy: 0.8077 - val_loss: 0.3846\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9352 - loss: 0.1871 - val_accuracy: 0.8846 - val_loss: 0.4237\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9498 - loss: 0.1713 - val_accuracy: 0.8846 - val_loss: 0.3769\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.1248 - val_accuracy: 0.8718 - val_loss: 0.4319\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9449 - loss: 0.1525 - val_accuracy: 0.8590 - val_loss: 0.3629\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1409 - val_accuracy: 0.8718 - val_loss: 0.4537\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9692 - loss: 0.0977 - val_accuracy: 0.8462 - val_loss: 0.6174\n",
      "Class weight: {0: 1.2955974842767295, 1: 1.2638036809815951, 2: 0.6959459459459459}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7249 - loss: 0.8225 - val_accuracy: 0.7662 - val_loss: 0.4487\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.5351 - val_accuracy: 0.8312 - val_loss: 0.4715\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8625 - loss: 0.3672 - val_accuracy: 0.8571 - val_loss: 0.3952\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8932 - loss: 0.2982 - val_accuracy: 0.8312 - val_loss: 0.4993\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.3104 - val_accuracy: 0.7792 - val_loss: 0.6093\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.3158 - val_accuracy: 0.8312 - val_loss: 0.6110\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.2750 - val_accuracy: 0.8701 - val_loss: 0.5103\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2120 - val_accuracy: 0.8442 - val_loss: 0.5463\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.2057 - val_accuracy: 0.8831 - val_loss: 0.5037\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9353 - loss: 0.1850 - val_accuracy: 0.8312 - val_loss: 0.5451\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9401 - loss: 0.1773 - val_accuracy: 0.8571 - val_loss: 0.5439\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9385 - loss: 0.1856 - val_accuracy: 0.8571 - val_loss: 0.4913\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9417 - loss: 0.1937 - val_accuracy: 0.8312 - val_loss: 0.5032\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9417 - loss: 0.1576 - val_accuracy: 0.8442 - val_loss: 0.5543\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ED759BA700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ED759BA700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Class weight: {0: 1.2955974842767295, 1: 1.2560975609756098, 2: 0.6983050847457627}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7023 - loss: 0.7710 - val_accuracy: 0.7922 - val_loss: 0.4905\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.5055 - val_accuracy: 0.7143 - val_loss: 0.5626\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8706 - loss: 0.3733 - val_accuracy: 0.7922 - val_loss: 0.5380\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8738 - loss: 0.3451 - val_accuracy: 0.8312 - val_loss: 0.4653\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.3526 - val_accuracy: 0.8052 - val_loss: 0.4173\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.2479 - val_accuracy: 0.7922 - val_loss: 0.3642\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.3013 - val_accuracy: 0.8052 - val_loss: 0.4646\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1919 - val_accuracy: 0.8182 - val_loss: 0.3621\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1683 - val_accuracy: 0.8312 - val_loss: 0.4464\n",
      "Class weight: {0: 1.2955974842767295, 1: 1.2560975609756098, 2: 0.6983050847457627}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7201 - loss: 0.8769 - val_accuracy: 0.7792 - val_loss: 0.4062\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.4793 - val_accuracy: 0.8312 - val_loss: 0.3411\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.4242 - val_accuracy: 0.8701 - val_loss: 0.2966\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8495 - loss: 0.4321 - val_accuracy: 0.8571 - val_loss: 0.3947\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.3086 - val_accuracy: 0.8182 - val_loss: 0.3322\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.2795 - val_accuracy: 0.8701 - val_loss: 0.3454\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.2546 - val_accuracy: 0.8571 - val_loss: 0.2675\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.2094 - val_accuracy: 0.8831 - val_loss: 0.3131\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9304 - loss: 0.1934 - val_accuracy: 0.8571 - val_loss: 0.3984\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9547 - loss: 0.1633 - val_accuracy: 0.8831 - val_loss: 0.2989\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1598 - val_accuracy: 0.8312 - val_loss: 0.4226\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9531 - loss: 0.1423 - val_accuracy: 0.9091 - val_loss: 0.3598\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9660 - loss: 0.1374 - val_accuracy: 0.8701 - val_loss: 0.3298\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.1542 - val_accuracy: 0.8831 - val_loss: 0.2668\n",
      "Epoch 15/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9595 - loss: 0.1404 - val_accuracy: 0.8571 - val_loss: 0.4750\n",
      "Epoch 16/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.1618 - val_accuracy: 0.8961 - val_loss: 0.3255\n",
      "Epoch 17/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9725 - loss: 0.1074 - val_accuracy: 0.8701 - val_loss: 0.3769\n",
      "Class weight: {0: 1.2955974842767295, 1: 1.2560975609756098, 2: 0.6983050847457627}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7039 - loss: 0.9059 - val_accuracy: 0.7662 - val_loss: 0.5164\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.4716 - val_accuracy: 0.8182 - val_loss: 0.4730\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 0.3744 - val_accuracy: 0.8182 - val_loss: 0.5025\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8673 - loss: 0.3477 - val_accuracy: 0.8182 - val_loss: 0.5062\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.2568 - val_accuracy: 0.8442 - val_loss: 0.4309\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.2325 - val_accuracy: 0.8701 - val_loss: 0.5936\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.2399 - val_accuracy: 0.8442 - val_loss: 0.4631\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9369 - loss: 0.2078 - val_accuracy: 0.8052 - val_loss: 0.4865\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1720 - val_accuracy: 0.7922 - val_loss: 0.5968\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9595 - loss: 0.1384 - val_accuracy: 0.8312 - val_loss: 0.5830\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9612 - loss: 0.1357 - val_accuracy: 0.8182 - val_loss: 0.5882\n",
      "Class weight: {0: 1.2955974842767295, 1: 1.2560975609756098, 2: 0.6983050847457627}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7184 - loss: 0.8081 - val_accuracy: 0.8182 - val_loss: 0.3675\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8204 - loss: 0.4507 - val_accuracy: 0.8182 - val_loss: 0.4487\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8722 - loss: 0.3421 - val_accuracy: 0.7662 - val_loss: 0.7783\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8722 - loss: 0.3325 - val_accuracy: 0.7792 - val_loss: 0.4815\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.3130 - val_accuracy: 0.8442 - val_loss: 0.4176\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.3030 - val_accuracy: 0.8442 - val_loss: 0.4530\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9207 - loss: 0.2216 - val_accuracy: 0.8052 - val_loss: 0.5184\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.2018 - val_accuracy: 0.8182 - val_loss: 0.4531\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1629 - val_accuracy: 0.8182 - val_loss: 0.6003\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.1464 - val_accuracy: 0.8182 - val_loss: 0.5573\n",
      "Class weight: {0: 1.2955974842767295, 1: 1.2560975609756098, 2: 0.6983050847457627}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 0.8201 - val_accuracy: 0.8571 - val_loss: 0.3412\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8317 - loss: 0.4572 - val_accuracy: 0.8571 - val_loss: 0.3346\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8770 - loss: 0.3568 - val_accuracy: 0.8571 - val_loss: 0.3210\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.3413 - val_accuracy: 0.8312 - val_loss: 0.3599\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8932 - loss: 0.2967 - val_accuracy: 0.8442 - val_loss: 0.3959\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8819 - loss: 0.3076 - val_accuracy: 0.8442 - val_loss: 0.3094\n",
      "Class weight: {0: 1.2875, 1: 1.2638036809815951, 2: 0.6983050847457627}\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7039 - loss: 0.8401 - val_accuracy: 0.7403 - val_loss: 0.6580\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.5832 - val_accuracy: 0.7792 - val_loss: 0.5240\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.4196 - val_accuracy: 0.7792 - val_loss: 0.5051\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8722 - loss: 0.3564 - val_accuracy: 0.8312 - val_loss: 0.4896\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9045 - loss: 0.2774 - val_accuracy: 0.7662 - val_loss: 0.5514\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8932 - loss: 0.2937 - val_accuracy: 0.7922 - val_loss: 0.4812\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.2608 - val_accuracy: 0.7792 - val_loss: 0.5534\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9159 - loss: 0.2218 - val_accuracy: 0.8182 - val_loss: 0.5327\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1824 - val_accuracy: 0.7662 - val_loss: 0.6693\n",
      "Class weight: {0: 1.293859649122807, 1: 1.2606837606837606, 2: 0.6973995271867612}\n",
      "Epoch 1/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7271 - loss: 0.8811 - val_accuracy: 0.8381 - val_loss: 0.3640\n",
      "Epoch 2/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8203 - loss: 0.5795 - val_accuracy: 0.8095 - val_loss: 0.3466\n",
      "Epoch 3/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.4192 - val_accuracy: 0.8381 - val_loss: 0.3382\n",
      "Epoch 4/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 0.3555 - val_accuracy: 0.8667 - val_loss: 0.3065\n",
      "Epoch 5/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.3191 - val_accuracy: 0.8571 - val_loss: 0.3296\n",
      "Epoch 6/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8898 - loss: 0.3200 - val_accuracy: 0.8190 - val_loss: 0.3368\n",
      "Epoch 7/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8814 - loss: 0.3346 - val_accuracy: 0.8476 - val_loss: 0.3552\n",
      "Epoch 8/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9068 - loss: 0.2799 - val_accuracy: 0.8762 - val_loss: 0.2935\n",
      "Epoch 9/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.2333 - val_accuracy: 0.8476 - val_loss: 0.3995\n",
      "Epoch 10/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.2017 - val_accuracy: 0.8762 - val_loss: 0.3165\n",
      "Epoch 11/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9373 - loss: 0.1838 - val_accuracy: 0.8667 - val_loss: 0.3003\n",
      "Epoch 12/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1740 - val_accuracy: 0.9143 - val_loss: 0.2577\n",
      "Epoch 13/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9390 - loss: 0.1873 - val_accuracy: 0.8762 - val_loss: 0.2773\n",
      "Epoch 14/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9458 - loss: 0.1774 - val_accuracy: 0.8476 - val_loss: 0.5247\n",
      "Epoch 15/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 0.1293 - val_accuracy: 0.8762 - val_loss: 0.5008\n",
      "Epoch 16/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9407 - loss: 0.1767 - val_accuracy: 0.8762 - val_loss: 0.4831\n",
      "Epoch 17/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9593 - loss: 0.1501 - val_accuracy: 0.9048 - val_loss: 0.3523\n",
      "NOTE: computed permutation importance on top-200 variance genes (out of 2000).\n",
      "Saved permutation importance CSVs + plots to: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\\20260105_181536\\final\n",
      "Saved run to: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\\20260105_181536\n",
      "Final model: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run\\20260105_181536\\final\\best_model.keras\n",
      "CV val accuracy: mean=0.8562 std=0.0328\n",
      "CV val macro F1: mean=0.8192 std=0.0436\n",
      "Test accuracy: 0.8130081295967102\n",
      "Test macro F1: 0.7623981054960934\n"
     ]
    }
   ],
   "source": [
    "#Now we call the main function to run the entire pipeline\n",
    "results, run_dir = main(expression_sup, samples_sup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699c79f",
   "metadata": {},
   "source": [
    "We examine the hyperparameters of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded4a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MLP_grade\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MLP_grade\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ expression (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">256,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ expression (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m256,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ softmax (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">793,739</span> (3.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m793,739\u001b[0m (3.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,579</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,579\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529,160</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m529,160\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at the best model \n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_025937\" #most recent model run folder\n",
    "model_path = os.path.join(run_dir, \"final\", \"best_model.keras\")\n",
    "\n",
    "model = load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d85ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'n_layers': 2,\n",
       " 'l2': 1e-05,\n",
       " 'lr': 0.001,\n",
       " 'dropout': 0.1,\n",
       " 'arch_mode': 'pyramid_half',\n",
       " 'units_l1': 8,\n",
       " 'units_l2': 8,\n",
       " 'base_units': 128,\n",
       " 'min_units': 8,\n",
       " 'units_l3': 64,\n",
       " 'units_l4': 16,\n",
       " 'units_l5': 256,\n",
       " 'units_l6': 256,\n",
       " 'tuner/epochs': 12,\n",
       " 'tuner/initial_epoch': 4,\n",
       " 'tuner/bracket': 4,\n",
       " 'tuner/round': 2,\n",
       " 'tuner/trial_id': '0116'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "hp_path = os.path.join(run_dir, \"best_hyperparameters.json\")\n",
    "with open(hp_path, \"r\") as f:\n",
    "    best_hp = json.load(f)\n",
    "\n",
    "best_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be7f65",
   "metadata": {},
   "source": [
    "We identify G2-G3 mismatches related to IDH mutation status and other molecular features included in our metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24848cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to identify G2/G3 cluster errors\n",
    "\n",
    "def load_ids_safely(path: str):\n",
    "    df = pd.read_csv(path)\n",
    "    ids = df.iloc[:, 0].astype(str).tolist()\n",
    "    ids = [i for i in ids if i not in (\"rownames\", \"index\", \"0\", \"None\") and i == i]\n",
    "    return ids\n",
    "\n",
    "def analyze_g2g3_cluster_errors(\n",
    "    run_dir: str,\n",
    "    expression_sup: pd.DataFrame,\n",
    "    samples_sup: pd.DataFrame,\n",
    "    label_col: str = \"tumor_grade\",\n",
    "    label_map: dict = None,\n",
    "    cluster_cols: list = None,\n",
    "):\n",
    "    if label_map is None:\n",
    "        label_map = {\"G2\": 0, \"G3\": 1, \"G4\": 2}\n",
    "\n",
    "    if cluster_cols is None:\n",
    "        cluster_cols = [\n",
    "            \"paper_Supervised.DNA.Methylation.Cluster\",\n",
    "            \"paper_IDH.specific.RNA.Expression.Cluster\",\n",
    "            \"paper_Pan.Glioma.DNA.Methylation.Cluster\",\n",
    "            \"paper_IDH.specific.DNA.Methylation.Cluster\",\n",
    "        ]\n",
    "\n",
    "    final_dir = os.path.join(run_dir, \"final\")\n",
    "    model_path = os.path.join(final_dir, \"best_model.keras\")\n",
    "    scaler_path = os.path.join(final_dir, \"scaler.joblib\")\n",
    "    test_ids_path = os.path.join(run_dir, \"test_ids.csv\")\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # id loading \n",
    "    test_ids = load_ids_safely(test_ids_path)\n",
    "\n",
    "    # keep only ids that exist in expression_sup\n",
    "    test_ids = [i for i in test_ids if i in expression_sup.index]\n",
    "\n",
    "    if len(test_ids) == 0:\n",
    "        raise ValueError(\"No valid test IDs matched expression_sup.index. Check test_ids.csv format.\")\n",
    "\n",
    "    X_test = expression_sup.loc[test_ids]\n",
    "\n",
    "    y_all = samples_sup[label_col].map(label_map)\n",
    "    y_test = y_all.loc[X_test.index].astype(int).to_numpy()\n",
    "\n",
    "    X_test_s = scaler.transform(X_test).astype(np.float32)\n",
    "    probs = model.predict(X_test_s, verbose=0)\n",
    "    y_pred = probs.argmax(axis=1)\n",
    "\n",
    "    cluster_cols = [c for c in cluster_cols if c in samples_sup.columns]\n",
    "    if len(cluster_cols) == 0:\n",
    "        raise ValueError(\"None of the requested cluster_cols exist in samples_sup.\")\n",
    "\n",
    "    pred_df = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_pred}, index=X_test.index)\n",
    "    pred_df = pred_df.join(samples_sup.loc[pred_df.index, cluster_cols])\n",
    "\n",
    "    g23 = pred_df[pred_df[\"y_true\"].isin([0, 1])].copy()\n",
    "    g23[\"error_type\"] = np.where(\n",
    "        g23[\"y_true\"] == g23[\"y_pred\"],\n",
    "        \"correct\",\n",
    "        np.where((g23[\"y_true\"] == 0) & (g23[\"y_pred\"] == 1), \"G2→G3\",\n",
    "        np.where((g23[\"y_true\"] == 1) & (g23[\"y_pred\"] == 0), \"G3→G2\", \"other\"))\n",
    "    )\n",
    "    g23[\"wrong_g2g3\"] = g23[\"error_type\"].isin([\"G2→G3\", \"G3→G2\"])\n",
    "\n",
    "    print(\"G2/G3 confusion counts:\")\n",
    "    print(g23[\"error_type\"].value_counts(dropna=False))\n",
    "\n",
    "    for col in cluster_cols:\n",
    "        s = g23[col].astype(\"string\").fillna(\"NA\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Cluster column: {col}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        counts = pd.crosstab(s, g23[\"wrong_g2g3\"])\n",
    "        print(\"\\nCounts (False=correct, True=G2<->G3 confused):\")\n",
    "        print(counts)\n",
    "\n",
    "        rates = pd.crosstab(s, g23[\"wrong_g2g3\"], normalize=\"index\")\n",
    "        rates = rates.reindex(columns=[False, True], fill_value=0.0)\n",
    "        rates.columns = [\"correct_rate\", \"g2g3_confusion_rate\"]\n",
    "\n",
    "\n",
    "\n",
    "        print(\"\\nPer-cluster rates:\")\n",
    "        print(rates)\n",
    "\n",
    "        dir_tab = pd.crosstab(s, g23[\"error_type\"])\n",
    "        print(\"\\nDirectional confusion:\")\n",
    "        print(dir_tab)\n",
    "\n",
    "    return pred_df, g23\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "082c9a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028F4EAFEE80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000028F4EAFEE80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "G2/G3 confusion counts:\n",
      "error_type\n",
      "correct    41\n",
      "G3→G2      11\n",
      "G2→G3       9\n",
      "other       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Cluster column: paper_Supervised.DNA.Methylation.Cluster\n",
      "================================================================================\n",
      "\n",
      "Counts (False=correct, True=G2<->G3 confused):\n",
      "wrong_g2g3                                False  True \n",
      "paper_Supervised.DNA.Methylation.Cluster              \n",
      "Classic-like                                  2      0\n",
      "Codel                                        14      7\n",
      "G-CIMP-high                                  20     12\n",
      "Mesenchymal-like                              5      0\n",
      "NA                                            1      0\n",
      "PA-like                                       2      1\n",
      "\n",
      "Per-cluster rates:\n",
      "                                          correct_rate  g2g3_confusion_rate\n",
      "paper_Supervised.DNA.Methylation.Cluster                                   \n",
      "Classic-like                                  1.000000             0.000000\n",
      "Codel                                         0.666667             0.333333\n",
      "G-CIMP-high                                   0.625000             0.375000\n",
      "Mesenchymal-like                              1.000000             0.000000\n",
      "NA                                            1.000000             0.000000\n",
      "PA-like                                       0.666667             0.333333\n",
      "\n",
      "Directional confusion:\n",
      "error_type                                G2→G3  G3→G2  correct  other\n",
      "paper_Supervised.DNA.Methylation.Cluster                              \n",
      "Classic-like                                  0      0        2      0\n",
      "Codel                                         3      4       14      0\n",
      "G-CIMP-high                                   5      7       19      1\n",
      "Mesenchymal-like                              0      0        4      1\n",
      "NA                                            0      0        0      1\n",
      "PA-like                                       1      0        2      0\n",
      "\n",
      "================================================================================\n",
      "Cluster column: paper_IDH.specific.RNA.Expression.Cluster\n",
      "================================================================================\n",
      "\n",
      "Counts (False=correct, True=G2<->G3 confused):\n",
      "wrong_g2g3                                 False  True \n",
      "paper_IDH.specific.RNA.Expression.Cluster              \n",
      "IDHmut-R1                                     12      5\n",
      "IDHmut-R2                                      5      1\n",
      "IDHmut-R3                                     17     13\n",
      "IDHwt-R1                                       1      0\n",
      "IDHwt-R2                                       2      0\n",
      "IDHwt-R3                                       3      0\n",
      "IDHwt-R4                                       3      1\n",
      "NA                                             1      0\n",
      "\n",
      "Per-cluster rates:\n",
      "                                           correct_rate  g2g3_confusion_rate\n",
      "paper_IDH.specific.RNA.Expression.Cluster                                   \n",
      "IDHmut-R1                                      0.705882             0.294118\n",
      "IDHmut-R2                                      0.833333             0.166667\n",
      "IDHmut-R3                                      0.566667             0.433333\n",
      "IDHwt-R1                                       1.000000             0.000000\n",
      "IDHwt-R2                                       1.000000             0.000000\n",
      "IDHwt-R3                                       1.000000             0.000000\n",
      "IDHwt-R4                                       0.750000             0.250000\n",
      "NA                                             1.000000             0.000000\n",
      "\n",
      "Directional confusion:\n",
      "error_type                                 G2→G3  G3→G2  correct  other\n",
      "paper_IDH.specific.RNA.Expression.Cluster                              \n",
      "IDHmut-R1                                      2      3       12      0\n",
      "IDHmut-R2                                      0      1        4      1\n",
      "IDHmut-R3                                      6      7       17      0\n",
      "IDHwt-R1                                       0      0        1      0\n",
      "IDHwt-R2                                       0      0        2      0\n",
      "IDHwt-R3                                       0      0        3      0\n",
      "IDHwt-R4                                       1      0        2      1\n",
      "NA                                             0      0        0      1\n",
      "\n",
      "================================================================================\n",
      "Cluster column: paper_Pan.Glioma.DNA.Methylation.Cluster\n",
      "================================================================================\n",
      "\n",
      "Counts (False=correct, True=G2<->G3 confused):\n",
      "wrong_g2g3                                False  True \n",
      "paper_Pan.Glioma.DNA.Methylation.Cluster              \n",
      "LGm1                                          4      1\n",
      "LGm2                                         19     14\n",
      "LGm3                                         11      4\n",
      "LGm4                                          2      0\n",
      "LGm5                                          5      0\n",
      "LGm6                                          2      1\n",
      "NA                                            1      0\n",
      "\n",
      "Per-cluster rates:\n",
      "                                          correct_rate  g2g3_confusion_rate\n",
      "paper_Pan.Glioma.DNA.Methylation.Cluster                                   \n",
      "LGm1                                          0.800000             0.200000\n",
      "LGm2                                          0.575758             0.424242\n",
      "LGm3                                          0.733333             0.266667\n",
      "LGm4                                          1.000000             0.000000\n",
      "LGm5                                          1.000000             0.000000\n",
      "LGm6                                          0.666667             0.333333\n",
      "NA                                            1.000000             0.000000\n",
      "\n",
      "Directional confusion:\n",
      "error_type                                G2→G3  G3→G2  correct  other\n",
      "paper_Pan.Glioma.DNA.Methylation.Cluster                              \n",
      "LGm1                                          1      0        3      1\n",
      "LGm2                                          6      8       19      0\n",
      "LGm3                                          1      3       11      0\n",
      "LGm4                                          0      0        2      0\n",
      "LGm5                                          0      0        4      1\n",
      "LGm6                                          1      0        2      0\n",
      "NA                                            0      0        0      1\n",
      "\n",
      "================================================================================\n",
      "Cluster column: paper_IDH.specific.DNA.Methylation.Cluster\n",
      "================================================================================\n",
      "\n",
      "Counts (False=correct, True=G2<->G3 confused):\n",
      "wrong_g2g3                                  False  True \n",
      "paper_IDH.specific.DNA.Methylation.Cluster              \n",
      "IDHmut-K1                                       4      1\n",
      "IDHmut-K2                                      16     11\n",
      "IDHmut-K3                                      14      7\n",
      "IDHwt-K1                                        2      0\n",
      "IDHwt-K2                                        5      0\n",
      "IDHwt-K3                                        2      1\n",
      "NA                                              1      0\n",
      "\n",
      "Per-cluster rates:\n",
      "                                            correct_rate  g2g3_confusion_rate\n",
      "paper_IDH.specific.DNA.Methylation.Cluster                                   \n",
      "IDHmut-K1                                       0.800000             0.200000\n",
      "IDHmut-K2                                       0.592593             0.407407\n",
      "IDHmut-K3                                       0.666667             0.333333\n",
      "IDHwt-K1                                        1.000000             0.000000\n",
      "IDHwt-K2                                        1.000000             0.000000\n",
      "IDHwt-K3                                        0.666667             0.333333\n",
      "NA                                              1.000000             0.000000\n",
      "\n",
      "Directional confusion:\n",
      "error_type                                  G2→G3  G3→G2  correct  other\n",
      "paper_IDH.specific.DNA.Methylation.Cluster                              \n",
      "IDHmut-K1                                       1      0        3      1\n",
      "IDHmut-K2                                       4      7       16      0\n",
      "IDHmut-K3                                       3      4       14      0\n",
      "IDHwt-K1                                        0      0        2      0\n",
      "IDHwt-K2                                        0      0        4      1\n",
      "IDHwt-K3                                        1      0        2      0\n",
      "NA                                              0      0        0      1\n"
     ]
    }
   ],
   "source": [
    "pred_df, g23_df = analyze_g2g3_cluster_errors(run_dir, expression_sup, samples_sup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f54da",
   "metadata": {},
   "source": [
    "Identify G2/G3 mismatches related to tumor subtype (Carcinoma, Astrocytoma, Oligodendroglioma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9eec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subtype_column(samples: pd.DataFrame,\n",
    "                       src_col: str = \"primary_diagnosis\",\n",
    "                       out_col: str = \"subtype\") -> pd.DataFrame:\n",
    "    \n",
    "    mapping = {\n",
    "        \"Papillary carcinoma, NOS\": \"Carcinoma\",\n",
    "        \"Basal cell carcinoma, NOS\": \"Carcinoma\",\n",
    "        \"Astrocytoma, NOS\": \"Astrocytoma\",\n",
    "        \"Astrocytoma, anaplastic\": \"Astrocytoma\",\n",
    "        \"Oligodendroglioma, NOS\": \"Oligodendroglioma\",\n",
    "        \"Oligodendroglioma, anaplastic\": \"Oligodendroglioma\",\n",
    "    }\n",
    "\n",
    "    s = samples[src_col].astype(\"string\")\n",
    "    samples[out_col] = s.replace(mapping).fillna(\"NA\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "def analyze_g2g3_subtype_errors_like_clusters(\n",
    "    g23: pd.DataFrame,\n",
    "    samples_sup: pd.DataFrame,\n",
    "    subtype_col: str = \"subtype\",\n",
    "    add_subtype: bool = True,\n",
    "    subtype_src_col: str = \"primary_diagnosis\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes existing g23 (output of analyze_g2g3_cluster_errors) and\n",
    "    prints per-subtype counts/rates/directional confusion\n",
    "    Returns g23 with subtype joined.\n",
    "    \"\"\"\n",
    "    samples2 = samples_sup.copy()\n",
    "    if add_subtype and subtype_col not in samples2.columns:\n",
    "        add_subtype_column(samples2, src_col=subtype_src_col, out_col=subtype_col)\n",
    "\n",
    "    # join subtype onto g23 (g23 already contains y_true/y_pred/error_type/wrong_g2g3)\n",
    "    g23_sub = g23.join(samples2[[subtype_col]], how=\"left\")\n",
    "    s = g23_sub[subtype_col].astype(\"string\").fillna(\"NA\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Subtype column: {subtype_col}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    counts = pd.crosstab(s, g23_sub[\"wrong_g2g3\"])\n",
    "    print(\"\\nCounts (False=correct, True=G2<->G3 confused):\")\n",
    "    print(counts)\n",
    "\n",
    "    rates = pd.crosstab(s, g23_sub[\"wrong_g2g3\"], normalize=\"index\")\n",
    "    rates = rates.reindex(columns=[False, True], fill_value=0.0)\n",
    "    rates.columns = [\"correct_rate\", \"g2g3_confusion_rate\"]\n",
    "    print(\"\\nPer-subtype rates:\")\n",
    "    print(rates)\n",
    "\n",
    "    dir_tab = pd.crosstab(s, g23_sub[\"error_type\"])\n",
    "    print(\"\\nDirectional confusion:\")\n",
    "    print(dir_tab)\n",
    "\n",
    "    return g23_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4061ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Subtype column: subtype\n",
      "================================================================================\n",
      "\n",
      "Counts (False=correct, True=G2<->G3 confused):\n",
      "wrong_g2g3         False  True \n",
      "subtype                        \n",
      "Astrocytoma           18      7\n",
      "Mixed glioma          13      5\n",
      "Oligodendroglioma     13      8\n",
      "\n",
      "Per-subtype rates:\n",
      "                   correct_rate  g2g3_confusion_rate\n",
      "subtype                                             \n",
      "Astrocytoma            0.720000             0.280000\n",
      "Mixed glioma           0.722222             0.277778\n",
      "Oligodendroglioma      0.619048             0.380952\n",
      "\n",
      "Directional confusion:\n",
      "error_type         G2→G3  G3→G2  correct  other\n",
      "subtype                                        \n",
      "Astrocytoma            2      5       18      0\n",
      "Mixed glioma           2      3       10      3\n",
      "Oligodendroglioma      5      3       13      0\n"
     ]
    }
   ],
   "source": [
    "g23_sub = analyze_g2g3_subtype_errors_like_clusters(\n",
    "    g23=g23_df,\n",
    "    samples_sup=samples_sup,\n",
    "    subtype_col=\"subtype\",\n",
    "    add_subtype=True,\n",
    "    subtype_src_col=\"primary_diagnosis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15dc64",
   "metadata": {},
   "source": [
    "Fisher's Exact Test to test if Grade2/Grade 3 misclassification varies significantly depending on IDH mutation status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d070c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_idh_wrong_g2g3_prefix(\n",
    "    g23: pd.DataFrame,\n",
    "    samples_sup: pd.DataFrame,\n",
    "    idh_col: str = \"paper_IDH.specific.RNA.Expression.Cluster\",\n",
    "    mut_prefix: str = \"IDHmut\",\n",
    "    wt_prefix: str = \"IDHwt\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Fisher exact test on 2x2 table:\n",
    "      rows = {IDH-mut, IDH-wt}\n",
    "      cols = {wrong_g2g3 0, 1}  (0=correct, 1=G2<->G3 confused)\n",
    "\n",
    "    Uses prefix matching on idh_col: startswith(mut_prefix) / startswith(wt_prefix)\n",
    "    \"\"\"\n",
    "\n",
    "    # Start from g23\n",
    "    df = g23.copy()\n",
    "\n",
    "    # Only join if the IDH column is not already in g23\n",
    "    if idh_col not in df.columns:\n",
    "        if idh_col not in samples_sup.columns:\n",
    "            raise ValueError(f\"idh_col='{idh_col}' not found in samples_sup.columns\")\n",
    "        df = df.join(samples_sup[[idh_col]], how=\"left\")\n",
    "\n",
    "    raw = df[idh_col].astype(\"string\").fillna(\"NA\")\n",
    "\n",
    "    def map_idh(v: str):\n",
    "        v = str(v)\n",
    "        if v.startswith(mut_prefix):\n",
    "            return \"IDH-mut\"\n",
    "        if v.startswith(wt_prefix):\n",
    "            return \"IDH-wt\"\n",
    "        return \"Other\"\n",
    "\n",
    "    df[\"IDH_bin\"] = raw.map(map_idh)\n",
    "    df = df[df[\"IDH_bin\"].isin([\"IDH-mut\", \"IDH-wt\"])].copy()\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\n",
    "            \"No rows remained after IDH prefix binning. \"\n",
    "            f\"Check idh_col='{idh_col}' and prefixes '{mut_prefix}', '{wt_prefix}'.\"\n",
    "        )\n",
    "\n",
    "    # Avoid boolean-column edge cases by using int 0/1\n",
    "    df[\"wrong_g2g3_int\"] = df[\"wrong_g2g3\"].astype(int)\n",
    "\n",
    "    ct = pd.crosstab(df[\"IDH_bin\"], df[\"wrong_g2g3_int\"])\n",
    "    ct = ct.reindex(index=[\"IDH-mut\", \"IDH-wt\"], columns=[0, 1], fill_value=0)\n",
    "\n",
    "    a = int(ct.loc[\"IDH-mut\", 1]); b = int(ct.loc[\"IDH-mut\", 0])\n",
    "    c = int(ct.loc[\"IDH-wt\",  1]); d = int(ct.loc[\"IDH-wt\",  0])\n",
    "\n",
    "    or_fisher, p = fisher_exact([[a, b], [c, d]], alternative=\"two-sided\")\n",
    "\n",
    "    tab = np.array([[a, b], [c, d]], dtype=float)\n",
    "    if (tab == 0).any():\n",
    "        tab = tab + 0.5\n",
    "    t = Table2x2(tab)\n",
    "    or_est = float(t.oddsratio)\n",
    "    ci_low, ci_high = map(float, t.oddsratio_confint(alpha=0.05))\n",
    "\n",
    "    out = {\n",
    "        \"idh_col\": idh_col,\n",
    "        \"n_total\": int(a + b + c + d),\n",
    "        \"IDH-mut_n\": int(a + b),\n",
    "        \"IDH-wt_n\": int(c + d),\n",
    "        \"IDH-mut_confused\": a,\n",
    "        \"IDH-wt_confused\": c,\n",
    "        \"IDH-mut_confusion_rate\": a / (a + b) if (a + b) else np.nan,\n",
    "        \"IDH-wt_confusion_rate\": c / (c + d) if (c + d) else np.nan,\n",
    "        \"odds_ratio\": or_est,\n",
    "        \"ci_low\": ci_low,\n",
    "        \"ci_high\": ci_high,\n",
    "        \"p_value\": float(p),\n",
    "    }\n",
    "    return out, ct, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20e463cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong_g2g3_int   0   1\n",
      "IDH_bin               \n",
      "IDH-mut         34  19\n",
      "IDH-wt           9   1\n",
      "{'idh_col': 'paper_IDH.specific.RNA.Expression.Cluster', 'n_total': 63, 'IDH-mut_n': 53, 'IDH-wt_n': 10, 'IDH-mut_confused': 19, 'IDH-wt_confused': 1, 'IDH-mut_confusion_rate': 0.3584905660377358, 'IDH-wt_confusion_rate': 0.1, 'odds_ratio': 5.029411764705882, 'ci_low': 0.5912022065276373, 'ci_high': 42.78567031664055, 'p_value': 0.14910919186671223}\n"
     ]
    }
   ],
   "source": [
    "idh_out, idh_ct, df_idh_used = fisher_idh_wrong_g2g3_prefix(\n",
    "    g23=g23_df,\n",
    "    samples_sup=samples_sup,\n",
    "    idh_col=\"paper_IDH.specific.RNA.Expression.Cluster\",\n",
    ")\n",
    "print(idh_ct)\n",
    "print(idh_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202f64c",
   "metadata": {},
   "source": [
    "Tumor Subtype association with Grade2/Grade 3 missclasification: chi-square and posthoc Fisher to test for significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6eee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtype_stats_wrong_g2g3_safe(\n",
    "    g23_sub: pd.DataFrame,\n",
    "    subtype_col: str = \"subtype\",\n",
    "    min_n_per_subtype: int = 5,\n",
    "):\n",
    "    df = g23_sub.copy()\n",
    "    df[subtype_col] = df[subtype_col].astype(\"string\").fillna(\"NA\")\n",
    "\n",
    "    # --- robust coercion to 0/1 (int) ---\n",
    "    if pd.api.types.is_bool_dtype(df[\"wrong_g2g3\"]):\n",
    "        df[\"wrong_g2g3_int\"] = df[\"wrong_g2g3\"].astype(int)\n",
    "    else:\n",
    "        s = df[\"wrong_g2g3\"].astype(\"string\").str.strip().str.lower()\n",
    "        m = {\"true\": 1, \"false\": 0, \"1\": 1, \"0\": 0, \"yes\": 1, \"no\": 0}\n",
    "        df[\"wrong_g2g3_int\"] = s.map(m)\n",
    "        if df[\"wrong_g2g3_int\"].isna().any():\n",
    "            bad = df.loc[df[\"wrong_g2g3_int\"].isna(), \"wrong_g2g3\"].head(10).tolist()\n",
    "            raise ValueError(f\"wrong_g2g3 has unmapped values (showing up to 10): {bad}\")\n",
    "        df[\"wrong_g2g3_int\"] = df[\"wrong_g2g3_int\"].astype(int)\n",
    "\n",
    "    # 0=correct, 1=confused\n",
    "    tab = pd.crosstab(df[subtype_col], df[\"wrong_g2g3_int\"])\n",
    "    tab = tab.reindex(columns=[0, 1], fill_value=0)\n",
    "\n",
    "    # Global chi-square\n",
    "    chi2, p_chi, dof, expected = chi2_contingency(tab.values)\n",
    "\n",
    "    # Posthoc: subtype vs rest (Fisher exact)\n",
    "    post = []\n",
    "    total_conf = int(tab[1].sum())\n",
    "    total_corr = int(tab[0].sum())\n",
    "\n",
    "    for st in tab.index:\n",
    "        n = int(tab.loc[st].sum())\n",
    "        if n < min_n_per_subtype:\n",
    "            continue\n",
    "\n",
    "        a = int(tab.loc[st, 1])  # confused in subtype\n",
    "        b = int(tab.loc[st, 0])  # correct  in subtype\n",
    "        a_rest = total_conf - a\n",
    "        b_rest = total_corr - b\n",
    "\n",
    "        p = fisher_exact([[a, b], [a_rest, b_rest]], alternative=\"two-sided\")[1]\n",
    "\n",
    "        ttab = np.array([[a, b], [a_rest, b_rest]], dtype=float)\n",
    "        if (ttab == 0).any():\n",
    "            ttab = ttab + 0.5\n",
    "        t2 = Table2x2(ttab)\n",
    "        or_est = float(t2.oddsratio)\n",
    "        ci_low, ci_high = map(float, t2.oddsratio_confint(alpha=0.05))\n",
    "\n",
    "        post.append({\n",
    "            \"subtype\": str(st),\n",
    "            \"n\": n,\n",
    "            \"confused\": a,\n",
    "            \"confusion_rate\": a / n if n else np.nan,\n",
    "            \"odds_ratio\": or_est,\n",
    "            \"ci_low\": ci_low,\n",
    "            \"ci_high\": ci_high,\n",
    "            \"p_value\": float(p),\n",
    "        })\n",
    "\n",
    "    post_df = pd.DataFrame(post).sort_values(\"p_value\").reset_index(drop=True)\n",
    "    if len(post_df) > 0:\n",
    "        post_df[\"q_value\"] = multipletests(post_df[\"p_value\"], method=\"fdr_bh\")[1]\n",
    "    else:\n",
    "        post_df[\"q_value\"] = []\n",
    "\n",
    "    return {\n",
    "        \"chi2\": float(chi2),\n",
    "        \"dof\": int(dof),\n",
    "        \"p_chi2\": float(p_chi),\n",
    "        \"contingency\": tab,\n",
    "        \"posthoc\": post_df,\n",
    "        \"expected\": expected,  \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f97bf1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong_g2g3_int      0  1\n",
      "subtype                 \n",
      "Astrocytoma        18  7\n",
      "Mixed glioma       13  5\n",
      "Oligodendroglioma  13  8\n",
      "{'chi2': 0.6819278499278499, 'dof': 2, 'p_chi2': 0.7110845601448692}\n",
      "             subtype   n  confused  confusion_rate  odds_ratio    ci_low  \\\n",
      "0  Oligodendroglioma  21         8        0.380952    1.589744  0.526852   \n",
      "1       Mixed glioma  18         5        0.277778    0.794872  0.239032   \n",
      "2        Astrocytoma  25         7        0.280000    0.777778  0.259437   \n",
      "\n",
      "    ci_high   p_value  q_value  \n",
      "0  4.796956  0.566441  0.78441  \n",
      "1  2.643251  0.773030  0.78441  \n",
      "2  2.331730  0.784410  0.78441  \n"
     ]
    }
   ],
   "source": [
    "sub_stats = subtype_stats_wrong_g2g3_safe(g23_sub=g23_sub, subtype_col=\"subtype\", min_n_per_subtype=5)\n",
    "\n",
    "print(sub_stats[\"contingency\"])\n",
    "print({\"chi2\": sub_stats[\"chi2\"], \"dof\": sub_stats[\"dof\"], \"p_chi2\": sub_stats[\"p_chi2\"]})\n",
    "print(sub_stats[\"posthoc\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa73f5a",
   "metadata": {},
   "source": [
    "Bar-plots summarizing the Fisher test and chi-square test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84202e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>comparison</th>\n",
       "      <th>n</th>\n",
       "      <th>estimate</th>\n",
       "      <th>OR [95% CI]</th>\n",
       "      <th>p_value</th>\n",
       "      <th>q_value_fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fisher exact</td>\n",
       "      <td>IDH-mut vs IDH-wt</td>\n",
       "      <td>63</td>\n",
       "      <td>5.029412</td>\n",
       "      <td>5.03 [0.59, 42.79]</td>\n",
       "      <td>0.149109</td>\n",
       "      <td>0.298218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chi-square</td>\n",
       "      <td>Subtype (global)</td>\n",
       "      <td>64</td>\n",
       "      <td>0.681928</td>\n",
       "      <td></td>\n",
       "      <td>0.711085</td>\n",
       "      <td>0.711085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test         comparison   n  estimate         OR [95% CI]  \\\n",
       "0  Fisher exact  IDH-mut vs IDH-wt  63  5.029412  5.03 [0.59, 42.79]   \n",
       "1    Chi-square   Subtype (global)  64  0.681928                       \n",
       "\n",
       "    p_value  q_value_fdr  \n",
       "0  0.149109     0.298218  \n",
       "1  0.711085     0.711085  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# sanity checks \n",
    "assert \"idh_out\" in globals(), \"Run the IDH Fisher step first to create `idh_out`.\"\n",
    "assert \"sub_stats\" in globals(), \"Run the subtype chi-square step first to create `sub_stats`.\"\n",
    "assert \"p_chi2\" in sub_stats, \"`sub_stats` must contain 'p_chi2' (global chi-square p-value).\"\n",
    "\n",
    "# Collect the two global tests\n",
    "p_idh = float(idh_out.get(\"p_value\", np.nan))\n",
    "p_sub = float(sub_stats.get(\"p_chi2\", np.nan))\n",
    "\n",
    "tests = pd.DataFrame([\n",
    "    {\n",
    "        \"test\": \"Fisher exact\",\n",
    "        \"comparison\": \"IDH-mut vs IDH-wt\",\n",
    "        \"n\": int(idh_out.get(\"n_total\", np.nan)) if pd.notna(idh_out.get(\"n_total\", np.nan)) else np.nan,\n",
    "        \"effect\": \"odds_ratio\",\n",
    "        \"estimate\": float(idh_out.get(\"odds_ratio\", np.nan)),\n",
    "        \"ci_low\": float(idh_out.get(\"ci_low\", np.nan)),\n",
    "        \"ci_high\": float(idh_out.get(\"ci_high\", np.nan)),\n",
    "        \"p_value\": p_idh,\n",
    "    },\n",
    "    {\n",
    "        \"test\": \"Chi-square\",\n",
    "        \"comparison\": \"Subtype (global)\",\n",
    "        \"n\": int(sub_stats[\"contingency\"].values.sum()) if \"contingency\" in sub_stats else np.nan,\n",
    "        \"effect\": \"chi2\",\n",
    "        \"estimate\": float(sub_stats.get(\"chi2\", np.nan)),\n",
    "        \"ci_low\": np.nan,\n",
    "        \"ci_high\": np.nan,\n",
    "        \"p_value\": p_sub,\n",
    "    },\n",
    "])\n",
    "\n",
    "# FDR adjust across these 2 global tests \n",
    "mask = tests[\"p_value\"].notna()\n",
    "tests[\"q_value_fdr\"] = np.nan\n",
    "if mask.sum() > 0:\n",
    "    tests.loc[mask, \"q_value_fdr\"] = multipletests(tests.loc[mask, \"p_value\"], method=\"fdr_bh\")[1]\n",
    "\n",
    "# OR column\n",
    "def fmt_or_ci(row):\n",
    "    if row[\"effect\"] != \"odds_ratio\" or pd.isna(row[\"estimate\"]):\n",
    "        return \"\"\n",
    "    return f\"{row['estimate']:.2f} [{row['ci_low']:.2f}, {row['ci_high']:.2f}]\"\n",
    "\n",
    "tests[\"OR [95% CI]\"] = tests.apply(fmt_or_ci, axis=1)\n",
    "\n",
    "report_df = tests[[\"test\", \"comparison\", \"n\", \"estimate\", \"OR [95% CI]\", \"p_value\", \"q_value_fdr\"]]\n",
    "display(report_df)\n",
    "\n",
    "# Bar plot \n",
    "plot_col = \"q_value_fdr\" if report_df[\"q_value_fdr\"].notna().any() else \"p_value\"\n",
    "\n",
    "plot_df = report_df[[\"comparison\", plot_col]].dropna().copy()\n",
    "plot_df[\"minus_log10\"] = -np.log10(plot_df[plot_col].clip(lower=1e-300))\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(plot_df[\"comparison\"], plot_df[\"minus_log10\"])\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.ylabel(f\"-log10(pval)\")\n",
    "plt.title(\"G2↔G3 misclassification association with IDH status and Tumor Subtype\")\n",
    "plt.axhline(-np.log10(0.05), linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b4d58",
   "metadata": {},
   "source": [
    "Bar Plot to show error rate in Grade2/Grade3 prediction according to IDH mutation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db01e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IDH contingency table \n",
    "tab = idh_ct.copy()\n",
    "\n",
    "# standardize columns to [0,1] where 1=confused, 0=correct\n",
    "if True in tab.columns or False in tab.columns:\n",
    "    tab = tab.rename(columns={False: 0, True: 1})\n",
    "tab = tab.reindex(columns=[0, 1], fill_value=0)\n",
    "\n",
    "n = tab.sum(axis=1)\n",
    "rate = tab[1] / n\n",
    "\n",
    "or_ = float(idh_out[\"odds_ratio\"])\n",
    "lo  = float(idh_out[\"ci_low\"])\n",
    "hi  = float(idh_out[\"ci_high\"])\n",
    "p   = float(idh_out[\"p_value\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.bar(rate.index.astype(str), rate.values)\n",
    "ax.set_ylabel(\"G2↔G3 confusion rate (confused / total)\")\n",
    "ax.set_ylim(0, max(0.5, float(rate.max()) * 1.4))\n",
    "\n",
    "# annotate n above bars\n",
    "for i, grp in enumerate(rate.index):\n",
    "    ax.text(i, rate.loc[grp] + 0.01, f\"n={int(n.loc[grp])}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "ax.set_title(f\"G2↔G3 confusion rate by IDH status\\nOR={or_:.2f}, p={p:.3g}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f43e65",
   "metadata": {},
   "source": [
    "Bar plot to show prediction rate in Grade2/Grade3 classification according to tumor subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ecee39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# expects: sub_stats dict with keys: chi2, dof, p_chi2, contingency\n",
    "tab = sub_stats[\"contingency\"].copy()   # rows=subtype, cols=0(correct),1(confused)\n",
    "tab = tab.reindex(columns=[0, 1], fill_value=0)\n",
    "\n",
    "# compute rates\n",
    "n = tab.sum(axis=1)\n",
    "rate = tab[1] / n\n",
    "\n",
    "chi2 = float(sub_stats[\"chi2\"])\n",
    "dof  = int(sub_stats[\"dof\"])\n",
    "p    = float(sub_stats[\"p_chi2\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "ax.bar(rate.index.astype(str), rate.values)\n",
    "ax.set_ylabel(\"G2↔G3 confusion rate (confused / total)\")\n",
    "ax.set_ylim(0, max(0.5, float(rate.max()) * 1.25))\n",
    "\n",
    "# annotate n above bars\n",
    "for i, (st, r) in enumerate(rate.items()):\n",
    "    ax.text(i, r + 0.01, f\"n={int(n.loc[st])}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "ax.set_title(f\"G2↔G3 confusion rate by subtype\\nGlobal χ²({dof})={chi2:.2f}, p={p:.3g}\")\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6ca5a",
   "metadata": {},
   "source": [
    "We reload the Keras Tuner Hyperband run, extract completed trials and their hyperparameters and construct diagnostic plots to overview how hyperparameters relate to the validation accuracy of the model (histogram of trial validation accuracies, Spearman correlation of hyperaparameters with validation accuracy, box plots of validation accuracy grouped by number of layers, dropout, batch size and maximum width). This requires having run the core functions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1c2f7536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\fold_01\\tuner\\grade_mlp\\tuner0.json\n",
      "Reloaded trials: 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\tuner_hist_val_accuracy.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\tuner_corr_val_accuracy.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joann\\AppData\\Local\\Temp\\ipykernel_53412\\1646129885.py:160: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(groups, labels=labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\tuner_box_n_layers_val_accuracy.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joann\\AppData\\Local\\Temp\\ipykernel_53412\\1646129885.py:160: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(groups, labels=labels)\n",
      "C:\\Users\\joann\\AppData\\Local\\Temp\\ipykernel_53412\\1646129885.py:160: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(groups, labels=labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\tuner_box_dropout_val_accuracy.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\tuner_box_batch_size_val_accuracy.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joann\\AppData\\Local\\Temp\\ipykernel_53412\\1646129885.py:160: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(groups, labels=labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\tuner_box_width_max_val_accuracy.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\" #most recent model run folder\n",
    "fold_for_tuner = 1\n",
    "project_name = \"grade_mlp\"\n",
    "\n",
    "objective_name = \"val_accuracy\"\n",
    "objective_direction = \"max\"\n",
    "\n",
    "tuner_dir = os.path.join(run_dir, f\"fold_{fold_for_tuner:02d}\", \"tuner\")\n",
    "\n",
    "# Assumes already defined in session:\n",
    "# - HyperbandWithBatchSize\n",
    "# - build_model\n",
    "# - expression_sup \n",
    "input_dim = expression_sup.shape[1]\n",
    "\n",
    "tuner = HyperbandWithBatchSize(\n",
    "    hypermodel=lambda hp: build_model(hp, input_dim=input_dim, num_classes=3),\n",
    "    objective=kt.Objective(objective_name, direction=objective_direction),\n",
    "    max_epochs=100,   \n",
    "    factor=3,         \n",
    "    directory=tuner_dir,\n",
    "    project_name=project_name,\n",
    "    overwrite=False\n",
    ")\n",
    "tuner.reload()\n",
    "print(\"Reloaded trials:\", len(tuner.oracle.trials))\n",
    "\n",
    "\n",
    "# Build dataframe of trials\n",
    "\n",
    "rows = []\n",
    "for trial_id, trial in tuner.oracle.trials.items():\n",
    "    if trial.score is None:\n",
    "        continue\n",
    "    d = dict(trial.hyperparameters.values)\n",
    "    d[\"trial_id\"] = trial_id\n",
    "    d[\"score\"] = float(trial.score)  \n",
    "    d[\"status\"] = trial.status\n",
    "    rows.append(d)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if df.empty:\n",
    "    raise ValueError(\"No trials with a score found. Check tuner_dir/project_name or objective_name.\")\n",
    "\n",
    "# stable order for plots\n",
    "df = df.sort_values(\"trial_id\").reset_index(drop=True)\n",
    "df[\"trial_num\"] = np.arange(1, len(df) + 1)\n",
    "\n",
    "# derived columns\n",
    "if \"lr\" in df.columns:\n",
    "    df[\"log_lr\"] = np.log10(df[\"lr\"].astype(float))\n",
    "if \"l2\" in df.columns:\n",
    "    df[\"log_l2\"] = np.where(df[\"l2\"].astype(float) > 0, np.log10(df[\"l2\"].astype(float)), np.nan)\n",
    "\n",
    "def reconstruct_units(row):\n",
    "    n_layers = int(row.get(\"n_layers\", 0) or 0)\n",
    "    if n_layers <= 0:\n",
    "        return []\n",
    "\n",
    "    # pyramid_half case\n",
    "    if \"base_units\" in row and pd.notna(row.get(\"base_units\")):\n",
    "        base = int(row[\"base_units\"])\n",
    "        min_u = int(row.get(\"min_units\", 8))\n",
    "        u = base\n",
    "        units = []\n",
    "        for _ in range(n_layers):\n",
    "            units.append(max(u, min_u))\n",
    "            u //= 2\n",
    "        return units\n",
    "\n",
    "    # free case\n",
    "    units = []\n",
    "    for i in range(1, n_layers + 1):\n",
    "        key = f\"units_l{i}\"\n",
    "        if key in row and pd.notna(row.get(key)):\n",
    "            units.append(int(row[key]))\n",
    "    return units\n",
    "\n",
    "df[\"width_max\"] = df.apply(lambda r: max(reconstruct_units(r), default=np.nan), axis=1)\n",
    "df[\"width_sum\"] = df.apply(lambda r: np.sum(reconstruct_units(r)) if reconstruct_units(r) else np.nan, axis=1)\n",
    "\n",
    "\n",
    "# 1) Histogram: trial val_accuracy distribution\n",
    "\n",
    "scores = df[\"score\"].to_numpy()\n",
    "best_score = scores.max()  \n",
    "mean_score = scores.mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.hist(scores, bins=20)\n",
    "ax.axvline(best_score, linestyle=\"--\", linewidth=2, label=f\"best = {best_score:.4f}\")\n",
    "ax.axvline(mean_score, linestyle=\":\", linewidth=2, label=f\"mean = {mean_score:.4f}\")\n",
    "ax.set_xlabel(objective_name)\n",
    "ax.set_ylabel(\"Count (trials)\")\n",
    "ax.set_title(f\"Distribution of {objective_name} across trials\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "out_hist = os.path.join(run_dir, f\"tuner_hist_{objective_name}.png\")\n",
    "fig.savefig(out_hist, dpi=200)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out_hist)\n",
    "\n",
    "\n",
    "# 2) Bar plot: Spearman correlation with val_accuracy\n",
    "# Positive rho => increasing HP tends to increase val_accuracy\n",
    "\n",
    "hp_candidates = [\"log_lr\", \"dropout\", \"log_l2\", \"n_layers\", \"batch_size\", \"base_units\", \"min_units\", \"width_max\", \"width_sum\"]\n",
    "hp_candidates = [c for c in hp_candidates if c in df.columns]\n",
    "\n",
    "corrs = []\n",
    "for c in hp_candidates:\n",
    "    tmp = df[[c, \"score\"]].dropna()\n",
    "    if len(tmp) < 3:\n",
    "        continue\n",
    "    rho = tmp[c].corr(tmp[\"score\"], method=\"spearman\")\n",
    "    corrs.append((c, rho))\n",
    "\n",
    "corrs = sorted(corrs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "labels = [c for c, _ in corrs]\n",
    "values = [rho for _, rho in corrs]\n",
    "x = np.arange(len(labels))\n",
    "ax.bar(x, values)\n",
    "ax.axhline(0, linewidth=1)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(f\"Spearman ρ with {objective_name}\")\n",
    "ax.set_title(f\"Hyperparameter association with {objective_name} (signed)\")\n",
    "fig.tight_layout()\n",
    "\n",
    "out_corr = os.path.join(run_dir, f\"tuner_corr_{objective_name}.png\")\n",
    "fig.savefig(out_corr, dpi=200)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out_corr)\n",
    "\n",
    "\n",
    "# 3) Box plots: val_accuracy grouped by key HPs\n",
    "\n",
    "def save_boxplot(group_col, out_name):\n",
    "    tmp = df[[group_col, \"score\"]].dropna().copy()\n",
    "    tmp[group_col] = tmp[group_col].astype(str)\n",
    "\n",
    "    groups = []\n",
    "    labels = []\n",
    "    for lab, g in tmp.groupby(group_col):\n",
    "        groups.append(g[\"score\"].values)\n",
    "        labels.append(lab)\n",
    "\n",
    "    # sort labels numerically if possible\n",
    "    try:\n",
    "        order = np.argsort([float(x) for x in labels])\n",
    "        labels = [labels[i] for i in order]\n",
    "        groups = [groups[i] for i in order]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.boxplot(groups, labels=labels)\n",
    "    ax.set_xlabel(group_col)\n",
    "    ax.set_ylabel(objective_name)\n",
    "    ax.set_title(f\"{objective_name} by {group_col}\")\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_path = os.path.join(run_dir, out_name)\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "if \"n_layers\" in df.columns:\n",
    "    save_boxplot(\"n_layers\", f\"tuner_box_n_layers_{objective_name}.png\")\n",
    "if \"dropout\" in df.columns:\n",
    "    save_boxplot(\"dropout\", f\"tuner_box_dropout_{objective_name}.png\")\n",
    "if \"batch_size\" in df.columns:\n",
    "    save_boxplot(\"batch_size\", f\"tuner_box_batch_size_{objective_name}.png\")\n",
    "\n",
    "if df[\"width_max\"].notna().any():\n",
    "    df[\"width_max_cat\"] = df[\"width_max\"].round().astype(\"Int64\").astype(str)\n",
    "    save_boxplot(\"width_max_cat\", f\"tuner_box_width_max_{objective_name}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd053703",
   "metadata": {},
   "source": [
    "Permutation Importance Graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e38f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_global_accuracy_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_global_macro_f1_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_f1_G2_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_recall_G2_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_f1_G3_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_recall_G3_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_f1_G4_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\perm_top10_recall_G4_gene_names.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\" #most recent model run folder\n",
    "final_dir = os.path.join(run_dir, \"final\")\n",
    "\n",
    "genes_path = r\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_genes.csv\"  \n",
    "# -----------------------\n",
    "\n",
    "# Load saved permutation importance tables produced above\n",
    "global_csv = os.path.join(final_dir, \"perm_importance_global.csv\")\n",
    "perclass_csv = os.path.join(final_dir, \"perm_importance_per_class.csv\")\n",
    "\n",
    "df_global = pd.read_csv(global_csv)\n",
    "df_per = pd.read_csv(perclass_csv)\n",
    "\n",
    "# Load gene mapping table\n",
    "genes = pd.read_csv(genes_path)\n",
    "\n",
    "#map ensembl IDs to gene names\n",
    "possible_ensembl_cols = [\"ensembl\", \"ensembl_id\", \"ensembl_gene_id\", \"gene_id\", \"GeneID\", \"Ensembl_ID\"]\n",
    "ensembl_col = None\n",
    "for c in possible_ensembl_cols:\n",
    "    if c in genes.columns:\n",
    "        ensembl_col = c\n",
    "        break\n",
    "\n",
    "# If not found, pick the first column that looks like Ensembl IDs\n",
    "if ensembl_col is None:\n",
    "    for c in genes.columns:\n",
    "        if genes[c].astype(str).str.startswith(\"ENSG\").any():\n",
    "            ensembl_col = c\n",
    "            break\n",
    "\n",
    "if ensembl_col is None:\n",
    "    raise ValueError(\n",
    "        \"Couldn't detect the Ensembl ID column in merged_genes.csv. \"\n",
    "        \"Please check the column names and set ensembl_col manually.\"\n",
    "    )\n",
    "\n",
    "if \"gene_name\" not in genes.columns:\n",
    "    raise ValueError(\"merged_genes.csv must contain a 'gene_name' column.\")\n",
    "\n",
    "# strip Ensembl version suffix: ENSG00000.12 -> ENSG00000\n",
    "def strip_version(s: str) -> str:\n",
    "    s = str(s)\n",
    "    return s.split(\".\")[0]\n",
    "\n",
    "genes[\"_ensembl_base\"] = genes[ensembl_col].map(strip_version)\n",
    "ens_to_name = (\n",
    "    genes.dropna(subset=[\"_ensembl_base\", \"gene_name\"])\n",
    "         .drop_duplicates(subset=[\"_ensembl_base\"])\n",
    "         .set_index(\"_ensembl_base\")[\"gene_name\"]\n",
    "         .to_dict()\n",
    ")\n",
    "\n",
    "def map_feature_label(ensembl_id: str) -> str:\n",
    "    base = strip_version(ensembl_id)\n",
    "    name = ens_to_name.get(base, None)\n",
    "    if name is None or str(name).strip() == \"\" or str(name).lower() == \"nan\":\n",
    "        return base  # fallback to ensembl if no mapping\n",
    "    return str(name)\n",
    "\n",
    "# Add gene_name column\n",
    "df_global[\"ensembl\"] = df_global[\"feature\"].map(strip_version)\n",
    "df_global[\"gene_name\"] = df_global[\"feature\"].map(map_feature_label)\n",
    "\n",
    "df_per[\"ensembl\"] = df_per[\"feature\"].map(strip_version)\n",
    "df_per[\"gene_name\"] = df_per[\"feature\"].map(map_feature_label)\n",
    "\n",
    "# Avoid duplicate labels: if gene_name repeats, append (ENSG...)\n",
    "def make_unique_labels(df):\n",
    "    counts = df[\"gene_name\"].value_counts()\n",
    "    dup = set(counts[counts > 1].index)\n",
    "    labels = []\n",
    "    for gn, ens in zip(df[\"gene_name\"], df[\"ensembl\"]):\n",
    "        if gn in dup:\n",
    "            labels.append(f\"{gn} ({ens})\")\n",
    "        else:\n",
    "            labels.append(gn)\n",
    "    return labels\n",
    "\n",
    "df_global[\"label\"] = make_unique_labels(df_global)\n",
    "df_per[\"label\"] = make_unique_labels(df_per)\n",
    "\n",
    "# Save renamed tables\n",
    "df_global.to_csv(os.path.join(final_dir, \"perm_importance_global_gene_names.csv\"), index=False)\n",
    "df_per.to_csv(os.path.join(final_dir, \"perm_importance_per_class_gene_names.csv\"), index=False)\n",
    "\n",
    "\n",
    "#Plots\n",
    "def bar_topk(df, score_col, std_col, title, filename, top_k=10):\n",
    "    d = df.sort_values(score_col, ascending=False).head(top_k).copy()\n",
    "    d = d.iloc[::-1]  # barh: biggest at top\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 0.4*len(d) + 2.5))\n",
    "    ax.barh(d[\"label\"].astype(str), d[score_col].to_numpy(), xerr=d[std_col].to_numpy())\n",
    "    ax.set_xlabel(\"Performance drop after permutation\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    out_path = os.path.join(final_dir, filename)\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "top_k = 10\n",
    "class_names = [\"G2\", \"G3\", \"G4\"]\n",
    "\n",
    "# Global plots\n",
    "bar_topk(\n",
    "    df_global, \"drop_accuracy_mean\", \"drop_accuracy_std\",\n",
    "    title=f\"Permutation importance (Global Accuracy) — Top {top_k}\",\n",
    "    filename=f\"perm_top{top_k}_global_accuracy_gene_names.png\",\n",
    "    top_k=top_k\n",
    ")\n",
    "bar_topk(\n",
    "    df_global, \"drop_macro_f1_mean\", \"drop_macro_f1_std\",\n",
    "    title=f\"Permutation importance (Global Macro-F1) — Top {top_k}\",\n",
    "    filename=f\"perm_top{top_k}_global_macro_f1_gene_names.png\",\n",
    "    top_k=top_k\n",
    ")\n",
    "\n",
    "# Per-class plots\n",
    "for cname in class_names:\n",
    "    bar_topk(\n",
    "        df_per,\n",
    "        f\"drop_f1_{cname}_mean\", f\"drop_f1_{cname}_std\",\n",
    "        title=f\"Permutation importance (Per-class F1: {cname}) — Top {top_k}\",\n",
    "        filename=f\"perm_top{top_k}_f1_{cname}_gene_names.png\",\n",
    "        top_k=top_k\n",
    "    )\n",
    "    bar_topk(\n",
    "        df_per,\n",
    "        f\"drop_recall_{cname}_mean\", f\"drop_recall_{cname}_std\",\n",
    "        title=f\"Permutation importance (Per-class Recall: {cname}) — Top {top_k}\",\n",
    "        filename=f\"perm_top{top_k}_recall_{cname}_gene_names.png\",\n",
    "        top_k=top_k\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f698a46",
   "metadata": {},
   "source": [
    "Integrated Gradient Importance to identify important genes for each grade prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _ig_batch(model, x, y, baseline, steps=32):\n",
    "    \"\"\"\n",
    "    Integrated Gradients for a batch.\n",
    "    x, baseline: (B, F) float32\n",
    "    y: (B,) int labels\n",
    "    returns: (B, F) IG attributions \n",
    "    \"\"\"\n",
    "    x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "    baseline = tf.convert_to_tensor(baseline, dtype=tf.float32)\n",
    "    y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "    alphas = tf.linspace(0.0, 1.0, steps + 1)\n",
    "    alphas = tf.reshape(alphas, (steps + 1, 1, 1))\n",
    "\n",
    "    x_exp = tf.expand_dims(x, axis=0)\n",
    "    b_exp = tf.expand_dims(baseline, axis=0)\n",
    "    x_interp = b_exp + alphas * (x_exp - b_exp)\n",
    "\n",
    "    S = steps + 1\n",
    "    B = tf.shape(x)[0]\n",
    "    F = tf.shape(x)[1]\n",
    "\n",
    "    x_flat = tf.reshape(x_interp, (S * B, F))\n",
    "    y_rep = tf.repeat(y, repeats=S)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x_flat)\n",
    "        preds = model(x_flat, training=False)\n",
    "        idx = tf.stack([tf.range(tf.shape(y_rep)[0]), y_rep], axis=1)\n",
    "        target = tf.gather_nd(preds, idx)\n",
    "\n",
    "    grads = tape.gradient(target, x_flat)\n",
    "    grads = tf.reshape(grads, (S, B, F))\n",
    "\n",
    "    grads_avg = (grads[:-1] + grads[1:]) / 2.0\n",
    "    avg_grads = tf.reduce_mean(grads_avg, axis=0)\n",
    "\n",
    "    ig = (x - baseline) * avg_grads\n",
    "    return ig.numpy()\n",
    "\n",
    "\n",
    "def integrated_gradients_importance_multiclass(\n",
    "    model,\n",
    "    X_s: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    feature_names,\n",
    "    out_dir: str,\n",
    "    class_names=(\"G2\", \"G3\", \"G4\"),\n",
    "    steps: int = 32,\n",
    "    batch_size: int = 128,\n",
    "    top_k: int = 10,\n",
    "    max_features: int | None = 200,  # only for reporting/plots, not for model input\n",
    "    baseline_mode: str = \"zeros\",\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    computes only absolute IG summaries\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    X_s = np.asarray(X_s, dtype=np.float32)\n",
    "    y = np.asarray(y).astype(int)\n",
    "\n",
    "    n_samples, n_features = X_s.shape\n",
    "    feature_names = np.array(list(feature_names), dtype=object)\n",
    "    if feature_names.shape[0] != n_features:\n",
    "        raise ValueError(\"feature_names length does not match X_s number of columns.\")\n",
    "\n",
    "    # baseline \n",
    "    if baseline_mode == \"zeros\":\n",
    "        baseline = np.zeros_like(X_s, dtype=np.float32)\n",
    "    elif baseline_mode == \"mean\":\n",
    "        baseline = np.tile(X_s.mean(axis=0, keepdims=True), (n_samples, 1)).astype(np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"baseline_mode must be 'zeros' or 'mean'\")\n",
    "\n",
    "    # compute IG on full feature set \n",
    "    abs_ig_all_full = np.zeros_like(X_s, dtype=np.float32)  # (N, F)\n",
    "\n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        xb = X_s[start:end]\n",
    "        yb = y[start:end]\n",
    "        bb = baseline[start:end]\n",
    "\n",
    "        ig_b = _ig_batch(model, xb, yb, bb, steps=steps)  # (B, F) signed\n",
    "        abs_ig_all_full[start:end] = np.abs(ig_b).astype(np.float32)\n",
    "\n",
    "    # choose features to REPORT (optional) \n",
    "    if (max_features is not None) and (n_features > max_features):\n",
    "        variances = X_s.var(axis=0)\n",
    "        feat_idx = np.argsort(-variances)[:max_features]\n",
    "        feat_idx = np.sort(feat_idx)\n",
    "        note = f\"NOTE: IG computed on ALL {n_features} features, but reporting top-{max_features} variance genes.\"\n",
    "    else:\n",
    "        feat_idx = np.arange(n_features)\n",
    "        note = f\"NOTE: IG computed and reported on all {n_features} features.\"\n",
    "\n",
    "    with open(os.path.join(out_dir, \"grad_importance_NOTE.txt\"), \"w\") as f:\n",
    "        f.write(note + \"\\n\")\n",
    "    print(note)\n",
    "\n",
    "    names_sel = feature_names[feat_idx]\n",
    "    abs_ig_sel = abs_ig_all_full[:, feat_idx]\n",
    "\n",
    "    # GLOBAL summary \n",
    "    df_global = pd.DataFrame({\n",
    "        \"feature\": names_sel,\n",
    "        \"mean_abs_ig\": abs_ig_sel.mean(axis=0),\n",
    "        \"std_abs_ig\":  abs_ig_sel.std(axis=0),\n",
    "    }).sort_values(\"mean_abs_ig\", ascending=False)\n",
    "\n",
    "    df_global.to_csv(os.path.join(out_dir, \"grad_importance_global_unsigned.csv\"), index=False)\n",
    "\n",
    "    # PER-CLASS summary \n",
    "    per_class_dfs = []\n",
    "    for c, cname in enumerate(class_names):\n",
    "        mask = (y == c)\n",
    "        if mask.sum() == 0:\n",
    "            tmp = pd.DataFrame({\n",
    "                \"feature\": names_sel,\n",
    "                f\"mean_abs_ig_{cname}\": np.nan,\n",
    "                f\"std_abs_ig_{cname}\":  np.nan,\n",
    "            })\n",
    "        else:\n",
    "            tmp = pd.DataFrame({\n",
    "                \"feature\": names_sel,\n",
    "                f\"mean_abs_ig_{cname}\": abs_ig_sel[mask].mean(axis=0),\n",
    "                f\"std_abs_ig_{cname}\":  abs_ig_sel[mask].std(axis=0),\n",
    "            })\n",
    "        per_class_dfs.append(tmp)\n",
    "\n",
    "    df_per_class = per_class_dfs[0]\n",
    "    for k in per_class_dfs[1:]:\n",
    "        df_per_class = df_per_class.merge(k, on=\"feature\")\n",
    "\n",
    "    df_per_class.to_csv(os.path.join(out_dir, \"grad_importance_unsigned_per_class.csv\"), index=False)\n",
    "\n",
    "    # plotting \n",
    "    def _bar_topk(df, score_col, title, filename, top_k=10):\n",
    "        d = df.sort_values(score_col, ascending=False).head(top_k).copy()\n",
    "        d = d.iloc[::-1]\n",
    "        fig, ax = plt.subplots(figsize=(8, 0.4 * len(d) + 2.5))\n",
    "        ax.barh(d[\"feature\"].astype(str), d[score_col].to_numpy())\n",
    "        ax.set_xlabel(\"Mean |Integrated Gradient|\")\n",
    "        ax.set_title(title)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(out_dir, filename), dpi=200)\n",
    "        plt.close(fig)\n",
    "\n",
    "    _bar_topk(\n",
    "        df_global,\n",
    "        score_col=\"mean_abs_ig\",\n",
    "        title=f\"Gradient importance (Global) — Top {top_k}\",\n",
    "        filename=f\"grad_top{top_k}_global.png\",\n",
    "        top_k=top_k\n",
    "    )\n",
    "\n",
    "    for cname in class_names:\n",
    "        _bar_topk(\n",
    "            df_per_class,\n",
    "            score_col=f\"mean_abs_ig_{cname}\",\n",
    "            title=f\"Gradient importance (Class {cname}) — Top {top_k}\",\n",
    "            filename=f\"grad_top{top_k}_{cname}.png\",\n",
    "            top_k=top_k\n",
    "        )\n",
    "\n",
    "    baseline_summary = {\n",
    "        \"note\": note,\n",
    "        \"method\": \"integrated_gradients\",\n",
    "        \"steps\": int(steps),\n",
    "        \"baseline_mode\": baseline_mode,\n",
    "        \"evaluated_features\": int(len(feat_idx)),\n",
    "        \"batch_size\": int(batch_size),\n",
    "        \"model_input_features\": int(n_features),\n",
    "    }\n",
    "    with open(os.path.join(out_dir, \"grad_importance_baseline.json\"), \"w\") as f:\n",
    "        json.dump(baseline_summary, f, indent=2)\n",
    "\n",
    "    print(\"Saved gradient importance CSVs + plots to:\", out_dir)\n",
    "    return df_global, df_per_class, baseline_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba688f",
   "metadata": {},
   "source": [
    "Run Gradient Importance Analysis. To do this we load the model saved locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b34877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: IG computed and reported on ALL 2000 features.\n",
      "Saved gradient importance CSVs + plots to: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final\\grad_importance\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\" #most recent model run folder\n",
    "final_dir = os.path.join(run_dir, \"final\")\n",
    "out_dir = os.path.join(final_dir, \"grad_importance\")\n",
    "\n",
    "# 1) load model\n",
    "model = load_model(os.path.join(final_dir, \"best_model.keras\"))\n",
    "\n",
    "# 2) load scaler\n",
    "scaler = joblib.load(os.path.join(final_dir, \"scaler.joblib\"))\n",
    "\n",
    "# 3) rebuild X_test and y_test \n",
    "test_ids = pd.read_csv(os.path.join(run_dir, \"test_ids.csv\")).iloc[:,0].astype(str).tolist()\n",
    "test_ids = [i for i in test_ids if i in expression_sup.index]\n",
    "\n",
    "label_map = {\"G2\":0, \"G3\":1, \"G4\":2}\n",
    "X_test = expression_sup.loc[test_ids]\n",
    "y_test = samples_sup.loc[X_test.index, \"tumor_grade\"].map(label_map).astype(int).to_numpy()\n",
    "\n",
    "X_test_s = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "# 4) run IG with all features reported\n",
    "df_g, df_pc, meta = integrated_gradients_importance_multiclass(\n",
    "    model=model,\n",
    "    X_s=X_test_s,\n",
    "    y=y_test,\n",
    "    feature_names=X_test.columns,\n",
    "    out_dir=out_dir,\n",
    "    class_names=(\"G2\",\"G3\",\"G4\"),\n",
    "    steps=32,\n",
    "    batch_size=128,\n",
    "    top_k=10,\n",
    "    max_features=None,     \n",
    "    baseline_mode=\"zeros\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597eb27",
   "metadata": {},
   "source": [
    "We Map ensembl IDs to Gene Names in the Gradient Importance summaries and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a12d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final/grad_importance\\grad_importance_global_gene_names.csv\n",
      " - C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final/grad_importance\\grad_importance_per_class_gene_names.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\" #most recent model run folder\n",
    "final_dir = os.path.join(run_dir, \"final/grad_importance\")\n",
    "\n",
    "genes_path = r\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_genes.csv\"  \n",
    "\n",
    "# gradient IG outputs (from IG functions above, saved locally)\n",
    "global_csv = os.path.join(final_dir, \"grad_importance_global_unsigned.csv\")\n",
    "perclass_csv = os.path.join(final_dir, \"grad_importance_unsigned_per_class.csv\")\n",
    "\n",
    "\n",
    "df_global = pd.read_csv(global_csv)\n",
    "df_per = pd.read_csv(perclass_csv)\n",
    "\n",
    "# Load gene mapping table\n",
    "genes = pd.read_csv(genes_path)\n",
    "\n",
    "#gene mapping\n",
    "possible_ensembl_cols = [\"ensembl\", \"ensembl_id\", \"ensembl_gene_id\", \"gene_id\", \"GeneID\", \"Ensembl_ID\"]\n",
    "ensembl_col = None\n",
    "for c in possible_ensembl_cols:\n",
    "    if c in genes.columns:\n",
    "        ensembl_col = c\n",
    "        break\n",
    "\n",
    "# If not found, pick the first column that looks like Ensembl IDs\n",
    "if ensembl_col is None:\n",
    "    for c in genes.columns:\n",
    "        if genes[c].astype(str).str.startswith(\"ENSG\").any():\n",
    "            ensembl_col = c\n",
    "            break\n",
    "\n",
    "if ensembl_col is None:\n",
    "    raise ValueError(\n",
    "        \"Couldn't detect the Ensembl ID column in merged_genes.csv. \"\n",
    "        \"Please check the column names and set ensembl_col manually.\"\n",
    "    )\n",
    "\n",
    "if \"gene_name\" not in genes.columns:\n",
    "    raise ValueError(\"merged_genes.csv must contain a 'gene_name' column.\")\n",
    "\n",
    "# strip Ensembl version suffix: ENSG00000.12 -> ENSG00000\n",
    "def strip_version(s: str) -> str:\n",
    "    s = str(s)\n",
    "    return s.split(\".\")[0]\n",
    "\n",
    "genes[\"_ensembl_base\"] = genes[ensembl_col].map(strip_version)\n",
    "ens_to_name = (\n",
    "    genes.dropna(subset=[\"_ensembl_base\", \"gene_name\"])\n",
    "         .drop_duplicates(subset=[\"_ensembl_base\"])\n",
    "         .set_index(\"_ensembl_base\")[\"gene_name\"]\n",
    "         .to_dict()\n",
    ")\n",
    "\n",
    "def map_feature_label(ensembl_id: str) -> str:\n",
    "    base = strip_version(ensembl_id)\n",
    "    name = ens_to_name.get(base, None)\n",
    "    if name is None or str(name).strip() == \"\" or str(name).lower() == \"nan\":\n",
    "        return base  # fallback to ensembl if no mapping\n",
    "    return str(name)\n",
    "\n",
    "# Add gene_name column\n",
    "df_global[\"ensembl\"] = df_global[\"feature\"].map(strip_version)\n",
    "df_global[\"gene_name\"] = df_global[\"feature\"].map(map_feature_label)\n",
    "\n",
    "df_per[\"ensembl\"] = df_per[\"feature\"].map(strip_version)\n",
    "df_per[\"gene_name\"] = df_per[\"feature\"].map(map_feature_label)\n",
    "\n",
    "# Avoid duplicate labels: if gene_name repeats, append (ENSG...)\n",
    "def make_unique_labels(df):\n",
    "    counts = df[\"gene_name\"].value_counts()\n",
    "    dup = set(counts[counts > 1].index)\n",
    "    labels = []\n",
    "    for gn, ens in zip(df[\"gene_name\"], df[\"ensembl\"]):\n",
    "        if gn in dup:\n",
    "            labels.append(f\"{gn} ({ens})\")\n",
    "        else:\n",
    "            labels.append(gn)\n",
    "    return labels\n",
    "\n",
    "df_global[\"label\"] = make_unique_labels(df_global)\n",
    "df_per[\"label\"] = make_unique_labels(df_per)\n",
    "\n",
    "# Save renamed tables\n",
    "df_global.to_csv(os.path.join(final_dir, \"grad_importance_global_gene_names.csv\"), index=False)\n",
    "df_per.to_csv(os.path.join(final_dir, \"grad_importance_per_class_gene_names.csv\"), index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", os.path.join(final_dir, \"grad_importance_global_gene_names.csv\"))\n",
    "print(\" -\", os.path.join(final_dir, \"grad_importance_per_class_gene_names.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b0f4f",
   "metadata": {},
   "source": [
    "Repeat the above for the plots presenting the top 10 most important genes per grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc4c0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final/grad_importance\\grad_top10_global_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final/grad_importance\\grad_top10_G2_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final/grad_importance\\grad_top10_G3_gene_names.png\n",
      "Saved: C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\\final/grad_importance\\grad_top10_G4_gene_names.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "run_dir = r\"C:/Users/joann/Desktop/M2/Deep_Learning/MLP_run/20260105_181536\"\n",
    "final_dir = os.path.join(run_dir, \"final/grad_importance\")\n",
    "\n",
    "genes_path = r\"C:/Users/joann/Desktop/M2/Deep_Learning/merged_genes.csv\"  \n",
    "\n",
    "# gradient IG outputs\n",
    "global_csv = os.path.join(final_dir, \"grad_importance_global_unsigned.csv\")\n",
    "perclass_csv = os.path.join(final_dir, \"grad_importance_unsigned_per_class.csv\")\n",
    "# -----------------------\n",
    "\n",
    "# Load IG tables\n",
    "df_global = pd.read_csv(global_csv)\n",
    "df_per = pd.read_csv(perclass_csv)\n",
    "\n",
    "# Load gene mapping table\n",
    "genes = pd.read_csv(genes_path)\n",
    "\n",
    "# gene mapping\n",
    "possible_ensembl_cols = [\"ensembl\", \"ensembl_id\", \"ensembl_gene_id\", \"gene_id\", \"GeneID\", \"Ensembl_ID\"]\n",
    "ensembl_col = None\n",
    "for c in possible_ensembl_cols:\n",
    "    if c in genes.columns:\n",
    "        ensembl_col = c\n",
    "        break\n",
    "\n",
    "if ensembl_col is None:\n",
    "    for c in genes.columns:\n",
    "        if genes[c].astype(str).str.startswith(\"ENSG\").any():\n",
    "            ensembl_col = c\n",
    "            break\n",
    "\n",
    "if ensembl_col is None:\n",
    "    raise ValueError(\n",
    "        \"Couldn't detect the Ensembl ID column in merged_genes.csv. \"\n",
    "        \"Please check the column names and set ensembl_col manually.\"\n",
    "    )\n",
    "\n",
    "if \"gene_name\" not in genes.columns:\n",
    "    raise ValueError(\"merged_genes.csv must contain a 'gene_name' column.\")\n",
    "\n",
    "def strip_version(s: str) -> str:\n",
    "    s = str(s)\n",
    "    return s.split(\".\")[0]\n",
    "\n",
    "genes[\"_ensembl_base\"] = genes[ensembl_col].map(strip_version)\n",
    "ens_to_name = (\n",
    "    genes.dropna(subset=[\"_ensembl_base\", \"gene_name\"])\n",
    "         .drop_duplicates(subset=[\"_ensembl_base\"])\n",
    "         .set_index(\"_ensembl_base\")[\"gene_name\"]\n",
    "         .to_dict()\n",
    ")\n",
    "\n",
    "def map_feature_label(ensembl_id: str) -> str:\n",
    "    base = strip_version(ensembl_id)\n",
    "    name = ens_to_name.get(base, None)\n",
    "    if name is None or str(name).strip() == \"\" or str(name).lower() == \"nan\":\n",
    "        return base\n",
    "    return str(name)\n",
    "\n",
    "# Add gene_name + label columns\n",
    "df_global[\"ensembl\"] = df_global[\"feature\"].map(strip_version)\n",
    "df_global[\"gene_name\"] = df_global[\"feature\"].map(map_feature_label)\n",
    "\n",
    "df_per[\"ensembl\"] = df_per[\"feature\"].map(strip_version)\n",
    "df_per[\"gene_name\"] = df_per[\"feature\"].map(map_feature_label)\n",
    "\n",
    "def make_unique_labels(df):\n",
    "    counts = df[\"gene_name\"].value_counts()\n",
    "    dup = set(counts[counts > 1].index)\n",
    "    labels = []\n",
    "    for gn, ens in zip(df[\"gene_name\"], df[\"ensembl\"]):\n",
    "        if gn in dup:\n",
    "            labels.append(f\"{gn} ({ens})\")\n",
    "        else:\n",
    "            labels.append(gn)\n",
    "    return labels\n",
    "\n",
    "df_global[\"label\"] = make_unique_labels(df_global)\n",
    "df_per[\"label\"] = make_unique_labels(df_per)\n",
    "\n",
    "# Save renamed tables\n",
    "df_global.to_csv(os.path.join(final_dir, \"grad_importance_global_gene_names.csv\"), index=False)\n",
    "df_per.to_csv(os.path.join(final_dir, \"grad_importance_per_class_gene_names.csv\"), index=False)\n",
    "\n",
    "#Plotting\n",
    "def bar_topk_noerr(df, score_col, title, filename, top_k=10, xlabel=\"Mean |Integrated Gradient|\"):\n",
    "    d = df.sort_values(score_col, ascending=False).head(top_k).copy()\n",
    "    d = d.iloc[::-1]  # barh: biggest at top\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 0.4*len(d) + 2.5))\n",
    "    ax.barh(d[\"label\"].astype(str), d[score_col].to_numpy())  # <-- no xerr\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    out_path = os.path.join(final_dir, filename)\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "top_k = 10\n",
    "class_names = [\"G2\", \"G3\", \"G4\"]\n",
    "\n",
    "# Global importance plot\n",
    "\n",
    "bar_topk_noerr(\n",
    "    df_global, \"mean_abs_ig\",\n",
    "    title=f\"Gradient importance (Global) — Top {top_k}\",\n",
    "    filename=f\"grad_top{top_k}_global_gene_names.png\",\n",
    "    top_k=top_k,\n",
    "    xlabel=\"Mean |Integrated Gradient|\"\n",
    ")\n",
    "\n",
    "# Per class plots\n",
    "for cname in class_names:\n",
    "    score_col = f\"mean_abs_ig_{cname}\"\n",
    "    if score_col not in df_per.columns:\n",
    "        print(f\"Skipping {cname}: column not found -> {score_col}\")\n",
    "        continue\n",
    "\n",
    "    bar_topk_noerr(\n",
    "        df_per, score_col,\n",
    "        title=f\"Gradient importance (Class {cname}) — Top {top_k}\",\n",
    "        filename=f\"grad_top{top_k}_{cname}_gene_names.png\",\n",
    "        top_k=top_k,\n",
    "        xlabel=\"Mean |Integrated Gradient|\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
